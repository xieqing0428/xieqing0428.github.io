<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/heart.svg" color="#222">
  <meta name="google-site-verification" content="G1zxL8_uEau107sKvFuMkecN7hNlJeQdhTqIaBuwQOI">
  <meta name="msvalidate.01" content="C1AB7AF43DCB682E2F23EDEDC4A54DCB">
  <meta name="baidu-site-verification" content="thkJPSuv5DFAoiiq">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=glyph-correction:300,300italic,400,400italic,700,700italic%7CAmstelvar:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CHanziPenSC-W5:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css" integrity="sha256-no0c5ccDODBwp+9hSmV5VvPpKwHCpbVzXHexIkupM6U=" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js" integrity="sha256-a5YRB27CcBwBFcT5EF/f3E4vzIqyHrSR878nseNYw64=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;alessa0.cn&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Pisces&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:true,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:true,&quot;lazyload&quot;:false,&quot;pangu&quot;:true,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:&quot;gitalk&quot;,&quot;storage&quot;:true,&quot;lazyload&quot;:true,&quot;nav&quot;:null,&quot;activeClass&quot;:&quot;gitalk&quot;},&quot;motion&quot;:{&quot;enable&quot;:false,&quot;async&quot;:true,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:5,&quot;unescape&quot;:false,&quot;preload&quot;:true}}</script><script src="/js/config.js"></script>
<meta name="description" content="HDFS1.0 与 MapReduce   troy-t-9sQgt_cR50c-unsplash">
<meta property="og:type" content="article">
<meta property="og:title" content="BigData 复习笔记 01：HDFS1.0 与 MapReduce">
<meta property="og:url" content="https://alessa0.cn/Tech/b2bff451d8c5/">
<meta property="og:site_name" content="听泉.ღ">
<meta property="og:description" content="HDFS1.0 与 MapReduce   troy-t-9sQgt_cR50c-unsplash">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://image.alessa0.cn/124000.jpg">
<meta property="og:image" content="https://image.alessa0.cn/150046.png">
<meta property="og:image" content="https://image.alessa0.cn/062837.png">
<meta property="og:image" content="https://image.alessa0.cn/071824.png">
<meta property="og:image" content="https://image.alessa0.cn/141922.png">
<meta property="article:published_time" content="2019-07-17T13:22:29.000Z">
<meta property="article:modified_time" content="2021-06-18T06:08:48.815Z">
<meta property="article:author" content="XIE QING">
<meta property="article:tag" content="BigData">
<meta property="article:tag" content="HDFS1.0">
<meta property="article:tag" content="MapReduce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://image.alessa0.cn/124000.jpg">


<link rel="canonical" href="https://alessa0.cn/Tech/b2bff451d8c5/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;alessa0.cn&#x2F;Tech&#x2F;b2bff451d8c5&#x2F;&quot;,&quot;path&quot;:&quot;Tech&#x2F;b2bff451d8c5&#x2F;&quot;,&quot;title&quot;:&quot;BigData 复习笔记 01：HDFS1.0 与 MapReduce&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>BigData 复习笔记 01：HDFS1.0 与 MapReduce | 听泉.ღ</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-125031312-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{&quot;tracking_id&quot;:&quot;UA-125031312-1&quot;,&quot;only_pageview&quot;:false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?e3a5e194c5c7cb7bbd97a2d5f0f44f33"></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">听泉.ღ</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">— 听泉小窝 —</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tech"><a href="/categories/Tech/" rel="section"><i class="fas fa-terminal fa-fw"></i>技术</a></li>
        <li class="menu-item menu-item-life"><a href="/categories/Life/" rel="section"><i class="fas fa-bed fa-fw"></i>生活</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%B5%81%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF"><span class="nav-number">1.</span> <span class="nav-text">海量数据分流处理技术</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9Fhash%E6%96%B9%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">传统 Hash 方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%92%E5%88%86"><span class="nav-number">1.2.</span> <span class="nav-text">随机划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7hash"><span class="nav-number">1.3.</span> <span class="nav-text">一致性 Hash</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mapreduce"><span class="nav-number">2.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E6%8F%90%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">前提：分布式存储架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="nav-number">2.2.</span> <span class="nav-text">MapReduce 基本思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><span class="nav-number">2.3.</span> <span class="nav-text">MapReduce 计算流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.3.1.</span> <span class="nav-text">步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.3.2.</span> <span class="nav-text">详解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="nav-number">2.3.3.</span> <span class="nav-text">配置注意事项</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce%E9%87%8D%E8%A6%81%E8%BF%9B%E7%A8%8Bhdfs1.0"><span class="nav-number">2.4.</span> <span class="nav-text">MapReduce 重要进程（HDFS1.0）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">2.5.</span> <span class="nav-text">MapReduce 作业提交流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6"><span class="nav-number">2.6.</span> <span class="nav-text">MapReduce 作业调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#streaming"><span class="nav-number">2.7.</span> <span class="nav-text">Streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">2.7.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">2.7.2.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A6%81%E7%82%B9"><span class="nav-number">2.7.3.</span> <span class="nav-text">命令行要点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hdfs1.0"><span class="nav-number">3.</span> <span class="nav-text">HDFS1.0</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#hdfs1.0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.1.</span> <span class="nav-text">HDFS1.0 基础</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.</span> <span class="nav-text">机架感知策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E6%A0%A1%E9%AA%8C"><span class="nav-number">3.3.</span> <span class="nav-text">数据完整性校验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%8E%AA%E6%96%BD"><span class="nav-number">3.4.</span> <span class="nav-text">可靠性措施</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hdfsmapreduce%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.5.</span> <span class="nav-text">HDFS&amp;MapReduce 本地模式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">4.</span> <span class="nav-text">案例代码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#wordcount"><span class="nav-number">4.1.</span> <span class="nav-text">WordCount</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python3"><span class="nav-number">4.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map.py"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#reduce.py"><span class="nav-number">4.1.1.2.</span> <span class="nav-text">reduce.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#the_man_of_property.txt"><span class="nav-number">4.1.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run.sh"><span class="nav-number">4.1.1.4.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#allsort_1reduce"><span class="nav-number">4.2.</span> <span class="nav-text">AllSort_1Reduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#version-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">Version 1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python3-1"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map_sort.py"><span class="nav-number">4.2.1.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red_sort.py"><span class="nav-number">4.2.1.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#a.txt"><span class="nav-number">4.2.1.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#b.txt"><span class="nav-number">4.2.1.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run.sh-1"><span class="nav-number">4.2.1.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#version-2"><span class="nav-number">4.2.2.</span> <span class="nav-text">Version 2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python3-2"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map_sort.py-1"><span class="nav-number">4.2.2.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red_sort.py-1"><span class="nav-number">4.2.2.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#a.txt-1"><span class="nav-number">4.2.2.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#b.txt-1"><span class="nav-number">4.2.2.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run.sh-2"><span class="nav-number">4.2.2.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#allsort"><span class="nav-number">4.3.</span> <span class="nav-text">AllSort</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python3-3"><span class="nav-number">4.3.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map_sort.py-2"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red_sort.py-2"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#a.txt-2"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#b.txt-2"><span class="nav-number">4.3.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run.sh-3"><span class="nav-number">4.3.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#file_broadcast"><span class="nav-number">4.4.</span> <span class="nav-text">File_Broadcast</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#file"><span class="nav-number">4.4.1.</span> <span class="nav-text">File</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python3-4"><span class="nav-number">4.4.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map.py-1"><span class="nav-number">4.4.1.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red.py"><span class="nav-number">4.4.1.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#the_man_of_property.txt-1"><span class="nav-number">4.4.1.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white_list"><span class="nav-number">4.4.1.1.4.</span> <span class="nav-text">white_list</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run.sh-4"><span class="nav-number">4.4.1.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cachefile"><span class="nav-number">4.4.2.</span> <span class="nav-text">cacheFile</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python3-5"><span class="nav-number">4.4.2.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map.py-2"><span class="nav-number">4.4.2.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red.py-1"><span class="nav-number">4.4.2.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#the_man_of_property.txt-2"><span class="nav-number">4.4.2.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white_list-1"><span class="nav-number">4.4.2.1.4.</span> <span class="nav-text">white_list</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run.sh-5"><span class="nav-number">4.4.2.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cachearchive"><span class="nav-number">4.4.3.</span> <span class="nav-text">cacheArchive</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python3-6"><span class="nav-number">4.4.3.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map.py-3"><span class="nav-number">4.4.3.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red.py-2"><span class="nav-number">4.4.3.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#the_man_of_property.txt-3"><span class="nav-number">4.4.3.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#w.tar.gz"><span class="nav-number">4.4.3.1.4.</span> <span class="nav-text">w.tar.gz</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#white_list_1"><span class="nav-number">4.4.3.1.4.1.</span> <span class="nav-text">white_list_1</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#white_list_2"><span class="nav-number">4.4.3.1.4.2.</span> <span class="nav-text">white_list_2</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run.sh-6"><span class="nav-number">4.4.3.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#compression"><span class="nav-number">4.5.</span> <span class="nav-text">Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python3-7"><span class="nav-number">4.5.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map.py-4"><span class="nav-number">4.5.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red.py-3"><span class="nav-number">4.5.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#the_man_of_property.txt-4"><span class="nav-number">4.5.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#white_list_dir.tar.gz"><span class="nav-number">4.5.1.4.</span> <span class="nav-text">white_list_dir.tar.gz</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#white_list_1-1"><span class="nav-number">4.5.1.4.1.</span> <span class="nav-text">white_list_1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white_list_2-1"><span class="nav-number">4.5.1.4.2.</span> <span class="nav-text">white_list_2</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run.sh-7"><span class="nav-number">4.5.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#join"><span class="nav-number">4.6.</span> <span class="nav-text">Join</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python3-8"><span class="nav-number">4.6.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map_a.py"><span class="nav-number">4.6.1.1.</span> <span class="nav-text">map_a.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#a.txt-3"><span class="nav-number">4.6.1.2.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#map_b.py"><span class="nav-number">4.6.1.3.</span> <span class="nav-text">map_b.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#b.txt-3"><span class="nav-number">4.6.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red_join.py"><span class="nav-number">4.6.1.5.</span> <span class="nav-text">red_join.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run.sh-8"><span class="nav-number">4.6.1.6.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%8A%A0%E9%A1%B9%E7%9B%AEpyweb"><span class="nav-number">4.7.</span> <span class="nav-text">附加项目：pyweb</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python3-9"><span class="nav-number">4.7.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#main.py"><span class="nav-number">4.7.1.1.</span> <span class="nav-text">main.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#file.test"><span class="nav-number">4.7.1.2.</span> <span class="nav-text">file.test</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="XIE QING"
      src="/images/logo.png">
  <p class="site-author-name" itemprop="name">XIE QING</p>
  <div class="site-description" itemprop="description">怜我世人, 焚我残躯。</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/xieqing0428" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xieqing0428" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/xieqing001" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;xieqing001" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.douban.com/people/xieqing0428" title="Douban → https:&#x2F;&#x2F;www.douban.com&#x2F;people&#x2F;xieqing0428" rel="noopener" target="_blank"><i class="fab fa-imdb fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xieqing0428@gmail.com" title="E-Mail → mailto:xieqing0428@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



          </div>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://alessa0.cn/Tech/b2bff451d8c5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo.png">
      <meta itemprop="name" content="XIE QING">
      <meta itemprop="description" content="怜我世人, 焚我残躯。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="听泉.ღ">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          BigData 复习笔记 01：HDFS1.0 与 MapReduce
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-07-17 21:22:29" itemprop="dateCreated datePublished" datetime="2019-07-17T21:22:29+08:00">2019-07-17</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-18 14:08:48" itemprop="dateModified" datetime="2021-06-18T14:08:48+08:00">2021-06-18</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
    </span>

  
    <span id="/Tech/b2bff451d8c5/" class="post-meta-item leancloud_visitors" data-flag-title="BigData 复习笔记 01：HDFS1.0 与 MapReduce" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>34k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>31 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p class="description">
HDFS1.0 与 MapReduce
</p>
<figure>
<img src="https://image.alessa0.cn/124000.jpg" alt="troy-t-9sQgt_cR50c-unsplash"><figcaption aria-hidden="true">troy-t-9sQgt_cR50c-unsplash</figcaption>
</figure>
<span id="more"></span>
<blockquote class="blockquote-center">
<p>Chapter01. MapReduce &amp; HDFS1.0</p>

</blockquote>
<h1 id="海量数据分流处理技术">海量数据分流处理技术</h1>
<blockquote>
<p>分而治之</p>
</blockquote>
<ul>
<li>大数据量
<ul>
<li>早期搜索引擎的网页存储系统，单机存储数千万网页，几十亿的网页需要通过几百台单机服务器存储，url 为 Key</li>
<li> 分布式文件系统，按 Block (64M-256M) 来划分组织文件
<ul>
<li>稳定性</li>
<li>容错能力</li>
<li>数据一致性</li>
</ul></li>
</ul></li>
<li>大流量
<ul>
<li>覆盖的大流量互联网服务</li>
<li>南方流量分到电信机房，北方流量分到联通机房</li>
<li>搜索引擎将 query 作为 Key 来分流</li>
</ul></li>
<li>大计算
<ul>
<li>根据输入数据划分计算任务</li>
<li> MapReduce 按输入数据来划分</li>
</ul></li>
</ul>
<h2 id="传统hash方法">传统 Hash 方法</h2>
<blockquote>
<p>如何将大数据流量均分到 N 台服务器，做到负载均衡？</p>
</blockquote>
<p>思路：</p>
<ul>
<li><p>找到合理的 Key，<strong>Hash(Key)</strong> 尽量分布均匀</p>
<ul>
<li><p>Hash (Key) mod N == 0 分到第 0 台</p></li>
<li><p> Hash (Key) mod N == 1 分到第 1 台</p></li>
<li><p>……</p></li>
<li><p>Hash (Key) mod N == i 分到第 i 台</p></li>
<li><p>……</p></li>
<li><p>Hash (Key) mod N == N - 1 分到第 N - 1 台</p></li>
</ul></li>
<li><p>一般以<strong>时间戳</strong>为 Key</p></li>
</ul>
<h2 id="随机划分">随机划分</h2>
<h2 id="一致性hash">一致性 Hash</h2>
<blockquote>
<p>支持动态增长， 更高级的划分方法，解决热点 (Hot spot) 问题</p>
</blockquote>
<p>案例：</p>
<ul>
<li>服务器 A 承压 50%</li>
<li> 服务器 B 承压 30%</li>
<li> 服务器 C 承压 20%</li>
</ul>
<p>如图，用户按 Hash (Key) 顺时针访问不同服务器。</p>
<ul>
<li><p>若服务器 B 挂掉，则</p>
<ul>
<li><p>服务器 B 承压 30% * 5/7 -&gt; 交付服务器 A</p></li>
<li><p> 服务器 B 承压 30% * 2/7 -&gt; 交付服务器 C</p></li>
</ul></li>
</ul>
<figure>
<img src="https://image.alessa0.cn/150046.png" alt="一致性Hash"><figcaption aria-hidden="true"> 一致性 Hash</figcaption>
</figure>
<h1 id="mapreduce">MapReduce</h1>
<blockquote>
<p>用于处理海量数据的<strong>分布式</strong>计算框架</p>
</blockquote>
<h2 id="前提分布式存储架构">前提：分布式存储架构</h2>
<p>角色：</p>
<ul>
<li>Master</li>
<li>Slave</li>
<li>Client</li>
</ul>
<figure>
<img src="https://image.alessa0.cn/062837.png" alt="GFS存储"><figcaption aria-hidden="true">GFS 存储</figcaption>
</figure>
<h2 id="mapreduce基本思想">MapReduce 基本思想</h2>
<blockquote>
<p>分而治之</p>
<blockquote>
<p>分解 &gt;&gt; 求解 &gt;&gt; 合并</p>
</blockquote>
</blockquote>
<p>案例 Demo：分面值数钞票</p>
<ul>
<li>方式 1: 单点策略
<ul>
<li>一个人数出所有的钞票，数出各面值各有多少张</li>
</ul></li>
<li>方式 2: 分治策略
<ul>
<li>每个人分得一部分钞票，数出各面值有多少张</li>
<li>汇总，每个人负责统计一种面值</li>
</ul></li>
</ul>
<h2 id="mapreduce计算流程">MapReduce 计算流程</h2>
<h3 id="步骤">步骤</h3>
<ol type="1">
<li>将数据输入到 HDFS 上</li>
<li>对输入数据进行处理</li>
<li>对处理的数据进行切片</li>
<li>根据就近原则，对切片数据进行对应节点的 Map 操作，结果暂存在内存缓冲区</li>
<li>当缓冲区数据大小到达阈值时
<ol type="1">
<li>锁住缓冲区</li>
<li>对切片结果按 partition 和 key 进行排序<strong>【默认快速排序，第一关键字为分区号，第二关键字为 key】</strong>，写入磁盘</li>
<li>将磁盘上的切片结果进行归并排序 {partition, key, value}</li>
</ol></li>
<li> 将 Map 结果按 partition 传输到对应 Reduce 节点</li>
<li> Reduce 节点将不同 Map 节点传输的数据按 partition 分区信息合并，进行 Reduce 操作</li>
<li>结果处理后输出到 HDFS</li>
</ol>
<h3 id="详解">详解</h3>
<ul>
<li>File
<ul>
<li>文件存储在 HDFS 中，每个文件切分成多个一定大小（默认 64M）的 Block，存储在多个 DataNode 节点上（默认 3 备份）</li>
<li>TextFile（明文标准输出）
<ul>
<li><code>hadoop fs -cat /xxx</code> 查看</li>
</ul></li>
<li> SequenceFile（二进制输出）
<ul>
<li><code>hadoop fs -text /xxx</code> 查看</li>
</ul></li>
</ul></li>
<li> InputFormat
<ul>
<li>MR 框架基础类之一（Java 接口）
<ul>
<li>数据分割（Data Splits）
<ul>
<li>每个 Split 包含后一个 Block 的开头部分的数据（解决记录跨 Block 问题）</li>
<li>如记录跨跃存储在两个 Block 中，这条记录属于前一个 Block 对应的 Split</li>
</ul></li>
<li> 记录读取器（Record Reader）
<ul>
<li>将读取到 Split 导入 Map</li>
<li> 每读取一条记录，将记录作为参数，调用一次 Map 函数</li>
<li>继续这个过程，读取下一条记录直到 Split 尾部</li>
</ul></li>
</ul></li>
</ul></li>
<li> Map</li>
<li>Shuffle
<ul>
<li>Partition， Sort， Spill， Merge， Combiner， Copy， Memory， Disk……</li>
<li><strong> 性能优化的重点</strong>
<ul>
<li> Partition
<ul>
<li>决定数据由哪个 Reducer 处理，从而分区（如 Hash 法）</li>
</ul></li>
<li>MemoryBuffer
<ul>
<li>内存缓冲区，每个 Map 的结果和 Partition 处理的 Key Value 结果都保存在缓存中</li>
<li>缓冲区大小：默认 100M</li>
<li> 溢写阈值：100M * 0.8 = 80M</li>
<li> 缓冲区中的数据：{partition, key, value} 三元组</li>
</ul></li>
<li> Spill
<ul>
<li>内存缓冲区达到阈值时，溢写 Spill 线程锁住这 80M 的缓冲区，开始将数据写到本地磁盘中，然后释放内存</li>
<li>每次溢写都生成一个数据文件</li>
<li>溢出的数据到磁盘前会对数据进行 Key 排序 Sort，以及合并 Combiner</li>
<li> 发送相同 Reduce 的 Key 数量，会拼接到一起，减少 Partition 的索引数量
<ul>
<li>Sort
<ul>
<li>缓冲区数据按照 Key 进行排序</li>
</ul></li>
<li> Combiner
<ul>
<li>数据合并，相同 Key 的数据，Value 值合并，减少输出传输量</li>
<li> Combiner 函数事实上是 Reducer 函数，满足 <strong>Combiner 处理不影响 {sum, max 等} 最终 Reduce 等结果时</strong>，可以极大提升性能</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li> Reduce
<ul>
<li>多个 Reduce 任务输入的数据都属于不同的 Partition，因此结果数据的 Key 不重复</li>
<li>合并 Reduce 输出文件即可得到最终的结果</li>
</ul></li>
</ul>
<h3 id="配置注意事项">配置注意事项</h3>
<ul>
<li>文件句柄个数
<ul>
<li>ulimit 命令</li>
<li>报错 “当前打开文件超出最大个数” 时使用</li>
</ul></li>
<li>合适的 slot
<ul>
<li>单机 map、reduce 个数【相互隔离】</li>
<li><code>mapred.tasktracker.map.tasks.maximum</code> 配置 Map 的 slot 数（默认 2）</li>
<li><code>mapreduce.tasktracker.tasks.reduce.maximum</code> 配置 Reduce 的 slot 数（默认 2）</li>
<li>内存限制</li>
<li> Slot 数 = CPU 核数 - 1</li>
<li> 多机集群分离</li>
</ul></li>
<li>磁盘情况
<ul>
<li>适合单机多磁盘（Raid 阵列）</li>
<li><code>mapred.local.dir</code>Map 中间结果存储路径</li>
<li><code>dfs.data.dir</code>HDFS 数据存储路径</li>
</ul></li>
<li>配置加载
<ul>
<li>简单配置通过提交作业时 - file 分发</li>
<li>复杂较大配置
<ul>
<li>传入 HDFS</li>
<li>Map 中打开文件读取</li>
<li>建立内存结构</li>
</ul></li>
</ul></li>
<li>确定 Map 任务数依次优先参考如下几个原则
<ul>
<li>每个 Map 任务使用的内存不超过 800M， 尽量在 500M 以下</li>
<li>每个 Map 任务运行时间控制在大约 20 分钟，最好 1-3 分钟</li>
<li>每个 Map 任务处理的最大数据量为一个 HDFS 块大小，一个 Map 任务处理的输入不能跨文件</li>
<li> Map 任务总数不能超过平台可用的任务槽位</li>
</ul></li>
<li> Map 要点
<ul>
<li>Map 个数为 Split 份数</li>
<li>压缩文件不可切分【通常压缩文件用于控制 Map 个数】</li>
<li>非压缩文件和 Sequence 文件可以切分</li>
<li><code>dfs.block.size</code> 决定 block 大小</li>
</ul></li>
<li>确定 Reduce 任务数依次优先参考如下几个原则
<ul>
<li>每个 Reduce 任务使用的内存不超过 800M， 尽量在 500M 以下</li>
<li>每个 Reduce 任务运行时间控制在大约 20 分钟，最好 1-3 分钟</li>
<li>整个 Reduce 阶段的输入数据总量</li>
<li>每个 Reduce 任务处理的数据量控制在 500M 以内</li>
<li> Map 任务数与 Reduce 任务数乘积</li>
<li>输出数据要求</li>
</ul></li>
<li> Reduce 个数设置
<ul>
<li><code>mapred.reduce.tasks</code> 默认为 1</li>
<li>Reduce 个数太少
<ul>
<li>单次执行慢</li>
<li>出错再试成本高</li>
</ul></li>
<li> Reduce 个数太大
<ul>
<li>Shuffle 开销大</li>
<li>输出大量小文件</li>
</ul></li>
</ul></li>
</ul>
<figure>
<img src="https://image.alessa0.cn/071824.png" alt="MapReduce"><figcaption aria-hidden="true"> MapReduce</figcaption>
</figure>
<h2 id="mapreduce重要进程hdfs1.0">MapReduce 重要进程（HDFS1.0）</h2>
<ul>
<li><strong>JobTracker</strong>
<ul>
<li> 主进程，负责接收客户作业提交，调度任务到作业节点上运行，并提供诸如监控工作节点状态及任务进度等管理功能，1 个 MapReduce 集群有 1 个 JobTracker，一般运行在可靠的硬件上</li>
<li> TaskTracker 是通过周期性的心跳来通知 JobTracker 其当前的健康状态，每一次心跳包含了可用的 map 和 reduce 任务数目，占用的数目及运行中任务的详细信息。JobTracker 利用一个<strong>线程池</strong>来<strong>同时</strong>处理心跳和客户请求。</li>
<li>等待 JobClient 提交作业</li>
</ul></li>
<li><strong> TaskTracker</strong>
<ul>
<li> 由 JobTracker 指派任务，实例化用户程序，在本地执行任务并周期性地向 JobTracker 汇报状态。在每一个工作节点上永远只会有 <strong>1 个</strong> TaskTracker。</li>
<li>每 3s 主动向 JobTracker 发送心跳询问有没有任务，如果有，让其派发任务给它执行</li>
</ul></li>
</ul>
<p>MapReduce 采用<strong>多进程</strong>并发</p>
<ul>
<li>优点：
<ul>
<li>方便任务资源控制和调配</li>
<li>运行稳定</li>
</ul></li>
<li>缺点：
<ul>
<li>消耗更多的启动时间【不适合低延时作业】</li>
</ul></li>
</ul>
<h2 id="mapreduce作业提交流程">MapReduce 作业提交流程</h2>
<ol type="1">
<li>客户端 Client 提交作业请求</li>
<li> Master 的 JobTracker 接收请求分配 Job ID</li>
<li> 客户端在 HDFS 对应 Job ID 目录上传资源</li>
<li> Client 向 JobTracker 正式提交任务</li>
<li> JobTracker 对任务进行初始化</li>
<li> JobTracker 将 HDFS 对应 Job ID 目录文件分发到各个 TaskTracker 节点</li>
<li> TaskTracker 向 JobTracker 发送心跳</li>
<li> TaskTracker 向 HDFS 分发 Job 资源</li>
<li> TaskTracker 执行任务</li>
</ol>
<h2 id="mapreduce作业调度">MapReduce 作业调度</h2>
<ul>
<li>默认<strong>先进先出（FIFO）</strong>队列调度模式
<ul>
<li>优先级：very_high, high, normal, low, very low</li>
</ul></li>
</ul>
<h2 id="streaming">Streaming</h2>
<blockquote>
<p>MapReduce 和 HDFS 采用 Java 实现，默认提供 Java 编程接口</p>
<p>Streaming 框架允许任何程序语言实现的程序在 Hadoop MapReduce 中使用</p>
<p>Streaming 方便已有程序向 Hadoop 平台移植</p>
</blockquote>
<h3 id="优点">优点</h3>
<ul>
<li>开发效率高
<ul>
<li>方便移植 Hadoop 平台，仅需按照一定的格式从标准输入读取数据，向标准输出写数据</li>
<li>原有单机程序稍加改动即可在 Hadoop 平台进行分布式处理</li>
<li>容易单机调试
<ul>
<li><code>cat input | mapper | sort | reducer &gt; output</code></li>
</ul></li>
</ul></li>
<li>便于平台进行资源控制
<ul>
<li>Streaming 框架中通过 limit 等方式可以灵活地限制应用程序使用的内存等资源</li>
</ul></li>
</ul>
<h3 id="缺点">缺点</h3>
<ul>
<li>Streaming 默认仅能处理文本数据，如要对二进制数据进行处理，比较好的方法是将二进制的 key 和 value 进行 base64 的编码转换成文本</li>
<li>两次数据拷贝和解析（分割），带来一定开销</li>
</ul>
<h3 id="命令行要点">命令行要点</h3>
<ul>
<li>input
<ul>
<li>指定作业的输入文件 HDFS 路径，支持使用 * 通配符，支持指定多个文件或目录，可多次使用</li>
</ul></li>
<li> output
<ul>
<li>指定作业的输出文件 HDFS 路径，路径必须不存在，并且执行作业用户需要具备创建该目录的权限，只能使用一次</li>
</ul></li>
<li> mapper
<ul>
<li>用户自己写的 Map 程序</li>
</ul></li>
<li> reducer
<ul>
<li>用户自己写的 Reduce 程序</li>
</ul></li>
<li> file
<ul>
<li>打包本地文件到提交的 Job 中
<ul>
<li>map 和 reduce 的执行文件</li>
<li> map 和 reduce 要用输入的文件，如配置文件</li>
</ul></li>
<li>类似的配置还有
<ul>
<li>cacheFile 提交 HDFS 文件到提交的 Job 中</li>
<li> cacheArchive 提交 HDFS 压缩文件到提交的 Job 中</li>
</ul></li>
</ul></li>
<li> jobconf
<ul>
<li>提交作业的一些配置属性</li>
<li>常见配置
<ul>
<li><code>mapred.map.tasks</code>map task 数目</li>
<li><code>mapred.reduce.tasks</code>reduce task 数目</li>
<li><code>stream.num.map.output.key.field</code> 指定 map task 输出记录中 key 所占的域数目</li>
<li><code>num.key.dields.for.partition</code> 指定对 key 分出来的前几部分做 partition 而不是整个 key</li>
</ul></li>
</ul></li>
</ul>
<h1 id="hdfs1.0">HDFS1.0</h1>
<h2 id="hdfs1.0基础">HDFS1.0 基础</h2>
<ul>
<li>HDFS1.0 系统架构
<ul>
<li>Master
<ul>
<li>NameNode
<ul>
<li>管理着文件系统命名空间
<ul>
<li>维护着文件系统树及树中的所有文件和目录</li>
</ul></li>
<li>存储元数据
<ul>
<li>NameNode 保存元信息的种类
<ul>
<li>文件名目录名及它们之间的层级关系</li>
<li>文件目录的所有者及其权限</li>
<li>每个文件块的名及文件有哪些块组成</li>
</ul></li>
</ul></li>
<li><strong>元数据保存在内存中</strong>
<ul>
<li> NameNode 元信息并不包含每个块的位置信息</li>
</ul></li>
<li>保存文件 / Block/DataNode 之间的<strong>映射</strong>关系
<ul>
<li>文件名 -&gt; Block</li>
<li>Block -&gt; DataNode</li>
</ul></li>
<li> 运行 NameNode 会占用大量内存和 I/O 资源，一般 NameNode 不会存储用户数据或执行 MapReduce 任务</li>
<li>全 Hadoop 系统仅一个 NameNode
<ul>
<li>单点问题
<ul>
<li>方案 1：将 Hadoop 元数据写入到本地文件系统时同步到远程挂载的网络文件系统 NFS</li>
<li> 方案 2：运行 SecondaryNameNode 进程，持久化到磁盘</li>
</ul></li>
</ul></li>
</ul></li>
<li> SecondaryNameNode
<ul>
<li><strong>并不是 NameNode</strong>，不取代 NameNode 也不是 NameNode 的备份</li>
<li>作用是与 NameNode 交互，定期通过编辑日志文件合并命名空间镜像</li>
<li>当 NameNode 发生故障，NameNode 会通过自己合并的命名空间镜像副本来恢复数据</li>
<li> SecondaryNameNode 保存的 NameNode 元信息总是<strong>滞后于 NameNode</strong> 的，会导致部分数据丢失</li>
</ul></li>
</ul></li>
<li> Worker
<ul>
<li>DataNode
<ul>
<li>保存 Block -&gt; Path 的映射关系</li>
<li>负责存储数据块，负责为系统客户端提供数据块的读写服务</li>
<li>根据 NameNode 的指示进行创建 / 删除和复制等操作</li>
<li>心跳机制，定期报告文件块列表信息</li>
<li> DataNode 间通信，进行块的副本处理
<ul>
<li>数据块
<ul>
<li>HDFS 默认数据块大小为 64M</li>
<li> 磁盘块一般为 512B</li>
<li> 块增大可以减少寻址时间，降低寻址时间 / 文件传输时间</li>
<li>数据块过大导致整体任务量过小，降低作业处理速度</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li> Hadoop 更倾向存储大文件
<ul>
<li>一般来说，一条元信息记录会占用 200byte 内存空间。</li>
<li>假设块大小为 64M，备份数量是 3，那么一个 1G 大小的文件将占用 16 * 3 = 48 个文件块</li>
<li>如现在有 1000 个 1M 大小的文件，则会占用 1000 * 3 = 3000 个文件块（多个文件不能放到一个块中）</li>
<li>如果文件越小，存储同等大小的文件所需要的元信息就越多</li>
</ul></li>
<li>元信息持久化
<ul>
<li>在 NameNode 中存放元信息的文件是 fsimage</li>
<li> 在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个文件 edits 中</li>
<li> fsimage 文件与 edits 文件会被 SecondaryNameNode 进程周期性合并</li>
</ul></li>
</ul>
<figure>
<img src="https://image.alessa0.cn/141922.png" alt="SecondaryNameNode"><figcaption aria-hidden="true"> SecondaryNameNode</figcaption>
</figure>
<h2 id="机架感知策略">机架感知策略</h2>
<blockquote>
<p>默认 3 副本</p>
</blockquote>
<ul>
<li>第一个副本，放在与客户端相同的节点（如客户端是集群外的一台机器，就随机算节点，但是系统会避免挑选太满或太忙的节点）</li>
<li>第二个副本，放在不同机架（随机选择）的节点</li>
<li>第三个副本，放在与第二个副本同机架但是不同节点上</li>
<li> distance
<ul>
<li>distance = 0, 相同 DataNode</li>
<li>distance = 2, 相同 Rack 下的不同 DataNode</li>
<li>distance = 4, 相同 IDC 下的不同 DataNode</li>
<li>distance = 6, 不同 IDC 下的 DataNode</li>
</ul></li>
</ul>
<h2 id="数据完整性校验">数据完整性校验</h2>
<ul>
<li><p>不希望在存储和处理数据时丢失或损坏任何数据</p></li>
<li><p> HDFS 会对写入的数据计算校验和，并在读取时验证校验和</p></li>
<li><p>两种校验方法</p>
<ul>
<li>校验和
<ul>
<li>检测损坏数据的常用方法时在第一次写入系统时计算数据的校验和，在通道传输过程中，如果新生成的校验和不完全匹配原始的校验和，那么数据就会被认定为是被损坏的（<strong>默认 512 字节创建 1 个校验码</strong>）</li>
</ul></li>
<li>数据块检测程序 DataBlockScanner
<ul>
<li>在 DataNode 节点上开启一个后台进程，来定期验证存储在它上的所有块，这个是防止物理介质出现损减情况而造成的数据损坏（损坏数据从其他 DataNode 拷贝）</li>
</ul></li>
</ul></li>
</ul>
<h2 id="可靠性措施">可靠性措施</h2>
<ul>
<li>一个名字节点和多个数据节点</li>
<li>数据复制（冗余机制）
<ul>
<li>存放位置（机架感知策略）</li>
<li>并不是 3 副本写完才返回 ack，三副本中有 1 个写成功就返回 ack</li>
</ul></li>
<li> 故障检测
<ul>
<li>数据节点
<ul>
<li>心跳包（检测是否宕机）</li>
<li>块报告（安全模式下检测）</li>
<li>数据完整性检测（校验和比较）</li>
</ul></li>
<li>名字节点
<ul>
<li>日志文件</li>
<li>镜像文件</li>
</ul></li>
</ul></li>
<li>空间回收机制
<ul>
<li>Trash 目录（修改 core-site.xml）</li>
</ul></li>
</ul>
<h2 id="hdfsmapreduce本地模式">HDFS&amp;MapReduce 本地模式</h2>
<ul>
<li>Master（小集群）
<ul>
<li>NameNode</li>
<li>JobTracker</li>
</ul></li>
<li>Slave
<ul>
<li>DataNode</li>
<li>TaskTracker</li>
</ul></li>
</ul>
<h1 id="案例代码">案例代码</h1>
<blockquote>
<p>常见实践有：</p>
<blockquote>
<p>数据统计</p>
<blockquote>
<p>WordCount</p>
</blockquote>
<p>数据过滤（清洗）</p>
<blockquote>
<p>从日志查找某一个条件等数据</p>
<p>除去非法数据，保留合法数据</p>
<p>数据格式整理</p>
</blockquote>
<p>同类汇聚</p>
<blockquote>
<p>多份日志，相同时间点、用户行为日志 Join</p>
<p>类表格文件存储中，相同主键拼接相关属性</p>
<p>历史的主数据与新增，修改数据合并</p>
</blockquote>
<p>全局排序</p>
<blockquote>
<p>混合日志，按时间排列好顺序</p>
<p>按某个或多个字段有序</p>
</blockquote>
<p>容错框架</p>
<blockquote>
<p>测试集群状态：在集群上运行一个错误代码 Job，进行观察</p>
<p>使用易出错的服务，365 * 24 运行</p>
<p>计算规模经常变化调整的服务</p>
<p>单进程程序，迅速提升执行计算效率</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="wordcount">WordCount</h2>
<h3 id="python3">Python3</h3>
<h4 id="map.py">map.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> ss:</span><br><span class="line">        <span class="built_in">print</span>(word.strip() + <span class="string">'\t'</span> + <span class="string">'1'</span>)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="reduce.py">reduce.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    word, cnt = ss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line">    <span class="keyword">if</span> current_word != word:</span><br><span class="line">        <span class="built_in">print</span>(current_word.strip() + <span class="string">'\t'</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line">        current_word = word</span><br><span class="line">        cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    cnt_sum += <span class="built_in">int</span>(cnt)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(current_word.strip() + <span class="string">'\t'</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="the_man_of_property.txt">The_Man_of_Property.txt</h4>
<figure class="highlight pgsql"><table><tbody><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></tbody></table></figure>
<h4 id="run.sh">run.sh</h4>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop命令地址</span></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop streaming jar包地址</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输入文件路径</span></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/01_mr_wordcount/The_Man_of_Property.txt"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输出文件路径</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/01_mr_wordcount/output/python3"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入文件本地路径</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/week01/01_mr_wordcount/The_Man_of_Property.txt"</span></span><br><span class="line"><span class="comment"># 输入文件 HDFS上传路径</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/01_mr_wordcount"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除HDFS存在目录</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建HDFS 上传目录</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="comment"># 将本地输入文件上传到HDFS目录</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py"</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># -file 过时了，2.8.5用-files代替，作为可选参数需放在-input等参数前面</span></span><br><span class="line"> </span><br></pre></td></tr></tbody></table></figure>
<h2 id="allsort_1reduce">AllSort_1Reduce</h2>
<h3 id="version-1">Version 1</h3>
<h4 id="python3-1">Python3</h4>
<h5 id="map_sort.py">map_sort.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + <span class="built_in">int</span>(key)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">str</span>(new_key) + <span class="string">'\t'</span> + val)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="red_sort.py">red_sort.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    new_key, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    key = <span class="built_in">int</span>(new_key) - base_count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'%s\t%s'</span> % (key, val))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="a.txt">a.txt</h5>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></tbody></table></figure>
<h5 id="b.txt">b.txt</h5>
<figure class="highlight mipsasm"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="run.sh-1">run.sh</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/version1/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_A}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_B}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH_A}</span>,<span class="variable">${INPUT_FILE_PATH_B}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 依赖MapReduce框架自身的sort功能：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1</span></span><br><span class="line">    <span class="comment"># -jobconf 可用-D 替代，作为可选参数放在-input等前面</span></span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h3 id="version-2">Version 2</h3>
<h4 id="python3-2">Python3</h4>
<h5 id="map_sort.py-1">map_sort.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="built_in">print</span>(line.strip())</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h5 id="red_sort.py-1">red_sort.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="built_in">print</span>(line.strip())</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h5 id="a.txt-1">a.txt</h5>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></tbody></table></figure>
<h5 id="b.txt-1">b.txt</h5>
<figure class="highlight mipsasm"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="run.sh-2">run.sh</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/version2/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_A}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_B}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span><br><span class="line">    -D stream.num.map.output.key.fields=1 \</span><br><span class="line">    -D mapreduce.partition.keypartitioner.options=<span class="string">"-k1,1"</span> \</span><br><span class="line">    -D mapreduce.partition.keycomparator.options=<span class="string">"-k1,1n"</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH_A}</span>,<span class="variable">${INPUT_FILE_PATH_B}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置单reduce：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1 \</span></span><br><span class="line">    <span class="comment"># 控制分发，完成二次排序：</span></span><br><span class="line">    <span class="comment"># -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span></span><br><span class="line">    <span class="comment"># 完成key排序：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=1 \</span></span><br><span class="line">    <span class="comment"># 选择哪一部分做partition，-k1,1表示partition的key范围是（1，1），即第1列</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options="-k1,1" \</span></span><br><span class="line">    <span class="comment"># 设置key中需要比较的字段或字节范围，-k1,1表示sort的key范围是（1，1），即第1列，n表示按数字number类型排序</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keycomparator.options="-k1,1n" \</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="allsort">AllSort</h2>
<h3 id="python3-3">Python3</h3>
<h4 id="map_sort.py-2">map_sort.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + <span class="built_in">int</span>(key)</span><br><span class="line"></span><br><span class="line">    partition_index = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> new_key &lt; (<span class="number">10100</span> + <span class="number">10000</span>) / <span class="number">2</span>:</span><br><span class="line">        partition_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t%s\t%s"</span> % (partition_index, new_key, val))</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h4 id="red_sort.py-2">red_sort.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    partition_index, new_key, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    key = <span class="built_in">int</span>(new_key) - base_count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'\t'</span>.join([<span class="built_in">str</span>(key), val]))</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="a.txt-2">a.txt</h4>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></tbody></table></figure>
<h4 id="b.txt-2">b.txt</h4>
<figure class="highlight mipsasm"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="run.sh-3">run.sh</h4>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/03_mr_allsort/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/03_mr_allsort/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/03_mr_allsort/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/03_mr_allsort/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/03_mr_allsort/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/03_mr_allsort/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_A}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_B}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH_A}</span>,<span class="variable">${INPUT_FILE_PATH_B}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value，此处以前2列为key</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=2 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（仅能从头顺序选取范围）用来做分发，此处以第1列做partition</span></span><br><span class="line">    <span class="comment"># -D num.key.fields.for.partition=1 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（可选择中间范围）用来做分发</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options="-k1,1" \</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="file_broadcast">File_Broadcast</h2>
<h3 id="file">File</h3>
<h4 id="python3-4">Python3</h4>
<h5 id="map.py-1">map.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="red.py">red.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="the_man_of_property.txt-1">The_Man_of_Property.txt</h5>
<figure class="highlight pgsql"><table><tbody><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></tbody></table></figure>
<h5 id="white_list">white_list</h5>
<figure class="highlight ebnf"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="run.sh-4">run.sh</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/file/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -files map.py,red.py,white_list \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func white_list"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="cachefile">cacheFile</h3>
<h4 id="python3-5">Python3</h4>
<h5 id="map.py-2">map.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">file</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    file_in = <span class="built_in">open</span>(file, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="red.py-1">red.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        word, cnt = ss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="built_in">print</span>(current_word.strip() + <span class="string">'\t'</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        cnt_sum += <span class="built_in">int</span>(cnt)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(current_word.strip() + <span class="string">'\t'</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="the_man_of_property.txt-2">The_Man_of_Property.txt</h5>
<figure class="highlight pgsql"><table><tbody><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></tbody></table></figure>
<h5 id="white_list-1">white_list</h5>
<figure class="highlight ebnf"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="run.sh-5">run.sh</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/cachefile/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/white_list"</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">"/week01/04_mr_file_broadcast/cachefile/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH_B}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${UPLOAD_PATH_A}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH_B}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachefile_demo \</span><br><span class="line">    -files map.py,red.py,<span class="string">"hdfs://master:9000/week01/04_mr_file_broadcast/cachefile/white_list#WH"</span> \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 过时了</span></span><br><span class="line">    <span class="comment"># -cacheFile "hdfs://master:9000/week01/04_mr_file_broadcast/cachefile</span></span><br><span class="line">    <span class="comment"># /white_list#WWWHHH" \</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#-cacheFile "${HDFS_FILE_PATH}#WH" \</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="cachearchive">cacheArchive</h3>
<h4 id="python3-6">Python3</h4>
<h5 id="map.py-3">map.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span>(<span class="params">f</span>):</span></span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span>(<span class="params">f</span>):</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">'/'</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="red.py-2">red.py</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h5 id="the_man_of_property.txt-3">The_Man_of_Property.txt</h5>
<figure class="highlight pgsql"><table><tbody><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></tbody></table></figure>
<h5 id="w.tar.gz">w.tar.gz</h5>
<h6 id="white_list_1">white_list_1</h6>
<figure class="highlight ebnf"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></tbody></table></figure>
<h6 id="white_list_2">white_list_2</h6>
<figure class="highlight css"><table><tbody><tr><td class="code"><pre><span class="line"><span class="selector-tag">a</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="run.sh-6">run.sh</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/cachearchive/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/w.tar.gz"</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">"/week01/04_mr_file_broadcast/cachearchive/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH_B}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${UPLOAD_PATH_A}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH_B}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachearchive_demo \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">"hdfs://master:9000/week01/04_mr_file_broadcast/cachearchive/w.tar.gz#WH.gz"</span> \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH.gz"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="compression">Compression</h2>
<h3 id="python3-7">Python3</h3>
<h4 id="map.py-4">map.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span>(<span class="params">f</span>):</span></span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span>(<span class="params">f</span>):</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">'/'</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="red.py-3">red.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t%s"</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="the_man_of_property.txt-4">The_Man_of_Property.txt</h4>
<figure class="highlight pgsql"><table><tbody><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></tbody></table></figure>
<h4 id="white_list_dir.tar.gz">white_list_dir.tar.gz</h4>
<h5 id="white_list_1-1">white_list_1</h5>
<figure class="highlight ebnf"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="white_list_2-1">white_list_2</h5>
<figure class="highlight css"><table><tbody><tr><td class="code"><pre><span class="line"><span class="selector-tag">a</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="run.sh-7">run.sh</h4>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/05_mr_compression/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/05_mr_compression/run_1/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/05_mr_compression/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/05_mr_compression/white_list_dir.tar.gz"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/05_mr_compression/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${OUTPUT_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=compression_run_1_demo \</span><br><span class="line">    -D mapreduce.map.output.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">"hdfs://master:9000/week01/05_mr_compression/white_list_dir.tar.gz#WH.gz"</span> \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH}</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH.gz"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h2 id="join">Join</h2>
<h3 id="python3-8">Python3</h3>
<h4 id="map_a.py">map_a.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">'	'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t1\t%s"</span> % (key, val))</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h4 id="a.txt-3">a.txt</h4>
<figure class="highlight apache"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">aaa1</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa2</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa3</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa4</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa5</span>	<span class="number">123</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="map_b.py">map_b.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">'	'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"%s\t2\t%s"</span> % (key, val))</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<h4 id="b.txt-3">b.txt</h4>
<figure class="highlight nginx"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">aaa1</span>	hadoop</span><br><span class="line">aaa2	hadoop</span><br><span class="line">aaa3	hadoop</span><br><span class="line">aaa4	hadoop</span><br><span class="line">aaa5	hadoop</span><br></pre></td></tr></tbody></table></figure>
<h4 id="red_join.py">red_join.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val_1 = <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, flag, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="string">'1'</span>:</span><br><span class="line">        val_1 = val</span><br><span class="line">    <span class="keyword">elif</span> flag == <span class="string">'2'</span>:</span><br><span class="line">        val_2 = val</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"%s\t%s\t%s"</span> % (key, val_1, val_2))</span><br><span class="line">        val_1 = <span class="string">""</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="run.sh-8">run.sh</h4>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/06_mr_join/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/06_mr_join/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_A=<span class="string">"/week01/06_mr_join/output/a/python3"</span></span><br><span class="line">OUTPUT_PATH_B=<span class="string">"/week01/06_mr_join/output/b/python3"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_JOIN=<span class="string">"/week01/06_mr_join/output/join/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/06_mr_join/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/06_mr_join/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/06_mr_join/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -rm -r -skipTrash <span class="variable">${INPUT_FILE_PATH_A}</span> <span class="variable">${INPUT_FILE_PATH_B}</span> <span class="variable">${OUTPUT_PATH_A}</span> <span class="variable">${OUTPUT_PATH_B}</span> <span class="variable">${OUTPUT_PATH_JOIN}</span></span><br><span class="line"></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -mkdir -p <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> fs -put <span class="variable">${LOCAL_FILE_PATH_A}</span> <span class="variable">${LOCAL_FILE_PATH_B}</span> <span class="variable">${UPLOAD_PATH}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -files map_a.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH_A}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH_A}</span> \</span><br><span class="line">    -mapper <span class="string">"python map_a.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2.</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -files map_b.py \</span><br><span class="line">    -input <span class="variable">${INPUT_FILE_PATH_B}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH_B}</span> \</span><br><span class="line">    -mapper <span class="string">"python map_b.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3.</span></span><br><span class="line"><span class="variable">${HADOOP_CMD}</span> jar <span class="variable">${STREAM_JAR_PATH}</span> \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files red_join.py \</span><br><span class="line">    -input <span class="variable">${OUTPUT_PATH_A}</span>,<span class="variable">${OUTPUT_PATH_B}</span> \</span><br><span class="line">    -output <span class="variable">${OUTPUT_PATH_JOIN}</span> \</span><br><span class="line">    -mapper <span class="string">"cat"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_join.py"</span> \</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="附加项目pyweb">附加项目：pyweb</h2>
<h3 id="python3-9">Python3</h3>
<p><strong>首先</strong>请确保使用 <code>pip install web.py==0.40-dev1</code></p>
<h4 id="main.py">main.py</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> web</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">urls = (</span><br><span class="line">    <span class="string">'/'</span>, <span class="string">'index'</span>,</span><br><span class="line">    <span class="string">'/test'</span>, <span class="string">'test'</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">app = web.application(urls, <span class="built_in">globals</span>())</span><br><span class="line"></span><br><span class="line">userid_rec_dict = {}</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'file.test'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        userid = ss[<span class="number">0</span>].strip()</span><br><span class="line">        items = ss[<span class="number">1</span>].strip()</span><br><span class="line">        userid_rec_dict[userid] = items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">index</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span>(<span class="params">self</span>):</span></span><br><span class="line">        params = web.<span class="built_in">input</span>()</span><br><span class="line">        userid = params.get(<span class="string">'userid'</span>, <span class="string">''</span>)</span><br><span class="line">        <span class="keyword">if</span> userid <span class="keyword">not</span> <span class="keyword">in</span> userid_rec_dict:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'no rec!'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'\n'</span>.join(userid_rec_dict[userid].strip().split(<span class="string">''</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(web.<span class="built_in">input</span>())</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'222'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app.run()</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="file.test">file.test</h4>
<figure class="highlight apache"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attribute">zhangsan</span>	<span class="number">1</span></span><br><span class="line"><span class="attribute">lisi</span>	<span class="number">2</span></span><br><span class="line"><span class="attribute">wangwu</span>	<span class="number">3</span></span><br></pre></td></tr></tbody></table></figure>
<p>在<strong>终端</strong>输入 <code>python main.py 12345</code> 启动 web 服务器</p>
<ul>
<li><p>如遇到报错信息</p></li>
<li><p> ``` Traceback (most recent call last): File "D:Files-packages.py", line 526, in take yield next(seq) StopIteration The above exception was the direct cause of the following exception: Traceback (most recent call last): File "D:.py", line 6, in <module> app = web.application(urls, globals(),True) File "D:Files-packages.py", line 62, in <strong>init</strong> self.init_mapping(mapping) File "D:Files-packages.py", line 130, in init_mapping self.mapping = list(utils.group(mapping, 2)) File "D:Files-packages.py", line 531, in group x = list(take(seq, size)) RuntimeError: generator raised StopIteration </module></p><figure class="highlight nim"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">修改<span class="type">Lib</span>\site-packages\web 下的utils.py文件</span><br><span class="line"></span><br><span class="line">```diff</span><br><span class="line">+ <span class="keyword">try</span>:</span><br><span class="line">      <span class="keyword">yield</span> next(<span class="built_in">seq</span>) <span class="comment"># 526行</span></span><br><span class="line">+ <span class="keyword">except</span> <span class="type">StopIteration</span>:</span><br><span class="line">+     <span class="keyword">return</span></span><br></pre></td></tr></tbody></table></figure><p></p></li>
</ul>
<p>在<strong>网页</strong>打开 <code>http://0.0.0.0:12345/</code> 即可访问页面</p>
<p>输入<strong>网址</strong><code>http://0.0.0.0:12345/?userid=zhangsan</code> 页面显示 <strong>1</strong></p>
<p>未来可拓展推荐系统 远程分词服务等</p>
<p><br></p>
<p><meting-js id="506092035" server="netease" type="song" preload="none"></meting-js></p>
<hr>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>XIE QING
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://alessa0.cn/Tech/b2bff451d8c5/" title="BigData 复习笔记 01：HDFS1.0 与 MapReduce">https://alessa0.cn/Tech/b2bff451d8c5/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/BigData/" rel="tag"><i class="fa fa-tag"></i> BigData</a>
              <a href="/tags/HDFS1-0/" rel="tag"><i class="fa fa-tag"></i> HDFS1.0</a>
              <a href="/tags/MapReduce/" rel="tag"><i class="fa fa-tag"></i> MapReduce</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/Tech/2df212192030/" rel="prev" title="BigData 复习笔记 00：系统架构与常见业务">
                  <i class="fa fa-chevron-left"></i> BigData 复习笔记 00：系统架构与常见业务
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/Tech/998c29cc79e2/" rel="next" title="BigData 复习笔记 02：TFIDF, LCS 与中文分词">
                  BigData 复习笔记 02：TFIDF, LCS 与中文分词 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">闽ICP备18014770号-1 </a>
      <img src="/images/gongan.png" alt=""><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=35018202000261" rel="noopener" target="_blank">闽公网安备35018202000261号 </a>
  </div>

<div class="copyright">
  &copy; 2017 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XIE QING</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">85k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:17</span>
  </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{&quot;object_url&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;pdfobject@2.2.5&#x2F;pdfobject.min.js&quot;,&quot;integrity&quot;:&quot;sha256-YuNlP9i6s&#x2F;WH7EaU2kErloo9Vc85C3WVqhoMDgsEVpY&#x3D;&quot;},&quot;url&quot;:&quot;&#x2F;lib&#x2F;pdf&#x2F;web&#x2F;viewer&quot;}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{&quot;enable&quot;:true,&quot;theme&quot;:&quot;forest&quot;,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mermaid@8.9.3&#x2F;dist&#x2F;mermaid.min.js&quot;,&quot;integrity&quot;:&quot;sha256-OyJHvRcZHaRR6Ig73ppxF4QXk8HzvfgTprRWkulCkfY&#x3D;&quot;}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script class="next-config" data-name="nprogress" type="application/json">{&quot;enable&quot;:true,&quot;spinner&quot;:true}</script>
  <script src="/js/third-party/nprogress.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{&quot;enable&quot;:true,&quot;app_id&quot;:&quot;spj45BlAacJErU9iVkUjBdMe-9Nh9j0Va&quot;,&quot;app_key&quot;:&quot;QxYREXarU2IotL8LwfVAPS0H&quot;,&quot;server_url&quot;:&quot;https:&#x2F;&#x2F;lean.alessa0.cn&quot;,&quot;security&quot;:false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;,&quot;integrity&quot;:&quot;sha256-ncNI9OXOS5Ek4tzVYiOMmN&#x2F;KKCPZ6V0Cpv2P&#x2F;zHntiA&#x3D;&quot;}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{&quot;enable&quot;:true,&quot;github_id&quot;:&quot;xieqing0428&quot;,&quot;repo&quot;:&quot;gitalk&quot;,&quot;client_id&quot;:&quot;ebff00f2118b2ecb19a1&quot;,&quot;client_secret&quot;:&quot;8ec8654b13829e1c459512086f65a6a31e67476e&quot;,&quot;admin_user&quot;:&quot;xieqing0428&quot;,&quot;distraction_free_mode&quot;:true,&quot;proxy&quot;:&quot;https:&#x2F;&#x2F;cors-anywhere.azm.workers.dev&#x2F;https:&#x2F;&#x2F;github.com&#x2F;login&#x2F;oauth&#x2F;access_token&quot;,&quot;language&quot;:&quot;zh-CN&quot;,&quot;js&quot;:{&quot;url&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;gitalk@1.7.2&#x2F;dist&#x2F;gitalk.min.js&quot;,&quot;integrity&quot;:&quot;sha256-Pmj85ojLaPOWwRtlMJwmezB&#x2F;Qg8BzvJp5eTzvXaYAfA&#x3D;&quot;},&quot;path_md5&quot;:&quot;189a625e20beab00ba28139f06038573&quot;}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
