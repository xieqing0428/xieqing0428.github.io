<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/heart.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"alessa0.cn","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="HDFS1.0与MapReduce ![troy-t-9sQgt_cR50c-unsplash](https:&#x2F;&#x2F;image.alessa0.cn&#x2F;124000.jpg)">
<meta property="og:type" content="article">
<meta property="og:title" content="BigData复习笔记01：HDFS1.0与MapReduce">
<meta property="og:url" content="https://alessa0.cn/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/BigData%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B001:HDFS1.0%E4%B8%8EMapReduce/">
<meta property="og:site_name" content="听泉.ღ">
<meta property="og:description" content="HDFS1.0与MapReduce ![troy-t-9sQgt_cR50c-unsplash](https:&#x2F;&#x2F;image.alessa0.cn&#x2F;124000.jpg)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://image.alessa0.cn/150046.png">
<meta property="og:image" content="https://image.alessa0.cn/062837.png">
<meta property="og:image" content="https://image.alessa0.cn/071824.png">
<meta property="og:image" content="https://image.alessa0.cn/141922.png">
<meta property="article:published_time" content="2019-07-17T13:22:29.000Z">
<meta property="article:modified_time" content="2021-06-17T09:32:03.142Z">
<meta property="article:author" content="XIE QING">
<meta property="article:tag" content="BigData">
<meta property="article:tag" content="HDFS1.0">
<meta property="article:tag" content="MapReduce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://image.alessa0.cn/150046.png">

<link rel="canonical" href="https://alessa0.cn/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/BigData%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B001:HDFS1.0%E4%B8%8EMapReduce/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>BigData复习笔记01：HDFS1.0与MapReduce | 听泉.ღ</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">听泉.ღ</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">— 听泉小窝 —</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://alessa0.cn/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/BigData%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B001:HDFS1.0%E4%B8%8EMapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XIE QING">
      <meta itemprop="description" content="怜我世人, 焚我残躯。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="听泉.ღ">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          BigData复习笔记01：HDFS1.0与MapReduce
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-17 21:22:29" itemprop="dateCreated datePublished" datetime="2019-07-17T21:22:29+08:00">2019-07-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-17 17:32:03" itemprop="dateModified" datetime="2021-06-17T17:32:03+08:00">2021-06-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">技术</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">复习笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p class="description">HDFS1.0与MapReduce</p>
![troy-t-9sQgt_cR50c-unsplash](https://image.alessa0.cn/124000.jpg)

<span id="more"></span>

<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>Chapter01. MapReduce &amp; HDFS1.0 </p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<h1 id="海量数据分流处理技术"><a href="#海量数据分流处理技术" class="headerlink" title="海量数据分流处理技术"></a>海量数据分流处理技术</h1><blockquote>
<p>分而治之</p>
</blockquote>
<ul>
<li><p>大数据量</p>
<ul>
<li>早期搜索引擎的网页存储系统，单机存储数千万网页，几十亿的网页需要通过几百台单机服务器存储，url为Key</li>
<li>分布式文件系统，按Block(64M-256M)来划分组织文件<ul>
<li>稳定性</li>
<li>容错能力</li>
<li>数据一致性</li>
</ul>
</li>
</ul>
</li>
<li><p>大流量</p>
<ul>
<li>覆盖的大流量互联网服务</li>
<li>南方流量分到电信机房，北方流量分到联通机房</li>
<li>搜索引擎将query作为Key来分流</li>
</ul>
</li>
<li><p>大计算</p>
<ul>
<li>根据输入数据划分计算任务</li>
<li>MapReduce 按输入数据来划分</li>
</ul>
</li>
</ul>
<h2 id="传统Hash方法"><a href="#传统Hash方法" class="headerlink" title="传统Hash方法"></a>传统Hash方法</h2><blockquote>
<p>如何将大数据流量均分到N台服务器，做到负载均衡？</p>
</blockquote>
<p>思路：</p>
<ul>
<li><p>找到合理的Key，**Hash(Key)**尽量分布均匀</p>
<ul>
<li><p>Hash(Key) mod N == 0 分到第 0 台</p>
</li>
<li><p>Hash(Key) mod N == 1 分到第 1 台</p>
</li>
<li><p>……</p>
</li>
<li><p>Hash(Key) mod N == i 分到第 i 台</p>
</li>
<li><p>……</p>
</li>
<li><p>Hash(Key) mod N == N - 1 分到第N - 1台</p>
</li>
</ul>
</li>
<li><p>一般以<strong>时间戳</strong>为Key</p>
</li>
</ul>
<h2 id="随机划分"><a href="#随机划分" class="headerlink" title="随机划分"></a>随机划分</h2><h2 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h2><blockquote>
<p>支持动态增长， 更高级的划分方法，解决热点(Hot spot)问题</p>
</blockquote>
<p>案例：</p>
<ul>
<li>服务器A承压50%</li>
<li>服务器B承压30%</li>
<li>服务器C承压20%</li>
</ul>
<p>如图，用户按Hash(Key)顺时针访问不同服务器。</p>
<ul>
<li><p>若服务器B挂掉，则</p>
<ul>
<li><p>服务器B承压30% * 5/7 -&gt; 交付服务器A </p>
</li>
<li><p>服务器B承压30% * 2/7 -&gt; 交付服务器C</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://image.alessa0.cn/150046.png" alt="一致性Hash"></p>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><blockquote>
<p>用于处理海量数据的<strong>分布式</strong>计算框架</p>
</blockquote>
<h2 id="前提：分布式存储架构"><a href="#前提：分布式存储架构" class="headerlink" title="前提：分布式存储架构"></a>前提：分布式存储架构</h2><p>角色：</p>
<ul>
<li>Master</li>
<li>Slave</li>
<li>Client</li>
</ul>
<p><img src="https://image.alessa0.cn/062837.png" alt="GFS存储"></p>
<h2 id="MapReduce基本思想"><a href="#MapReduce基本思想" class="headerlink" title="MapReduce基本思想"></a>MapReduce基本思想</h2><blockquote>
<p>分而治之</p>
<blockquote>
<p>分解 &gt;&gt; 求解 &gt;&gt; 合并</p>
</blockquote>
</blockquote>
<p>案例Demo：分面值数钞票</p>
<ul>
<li><p>方式1: 单点策略</p>
<ul>
<li>一个人数出所有的钞票，数出各面值各有多少张</li>
</ul>
</li>
<li><p>方式2: 分治策略</p>
<ul>
<li>每个人分得一部分钞票，数出各面值有多少张</li>
<li>汇总，每个人负责统计一种面值</li>
</ul>
</li>
</ul>
<h2 id="MapReduce计算流程"><a href="#MapReduce计算流程" class="headerlink" title="MapReduce计算流程"></a>MapReduce计算流程</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>将数据输入到HDFS上</li>
<li>对输入数据进行处理</li>
<li>对处理的数据进行切片</li>
<li>根据就近原则，对切片数据进行对应节点的Map操作，结果暂存在内存缓冲区</li>
<li>当缓冲区数据大小到达阈值时<ol>
<li>锁住缓冲区</li>
<li>对切片结果按partition和key进行排序<strong>【默认快速排序，第一关键字为分区号，第二关键字为key】</strong>，写入磁盘</li>
<li>将磁盘上的切片结果进行归并排序{partition, key, value}</li>
</ol>
</li>
<li>将Map结果按partition传输到对应Reduce节点</li>
<li>Reduce节点将不同Map节点传输的数据按partition分区信息合并，进行Reduce操作</li>
<li>结果处理后输出到HDFS</li>
</ol>
<h3 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h3><ul>
<li>File<ul>
<li>文件存储在HDFS中，每个文件切分成多个一定大小（默认64M）的Block，存储在多个DataNode节点上（默认3备份）</li>
<li>TextFile（明文标准输出）<ul>
<li><code>hadoop fs -cat /xxx</code>查看</li>
</ul>
</li>
<li>SequenceFile（二进制输出）<ul>
<li><code>hadoop fs -text /xxx</code>查看</li>
</ul>
</li>
</ul>
</li>
<li>InputFormat<ul>
<li>MR框架基础类之一（Java接口）<ul>
<li>数据分割（Data Splits）<ul>
<li>每个Split包含后一个Block的开头部分的数据（解决记录跨Block问题）</li>
<li>如记录跨跃存储在两个Block中，这条记录属于前一个Block对应的Split</li>
</ul>
</li>
<li>记录读取器（Record Reader）<ul>
<li>将读取到Split导入Map</li>
<li>每读取一条记录，将记录作为参数，调用一次Map函数</li>
<li>继续这个过程，读取下一条记录直到Split尾部</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Map</li>
<li>Shuffle<ul>
<li>Partition， Sort， Spill， Merge， Combiner， Copy， Memory， Disk……</li>
<li><strong>性能优化的重点</strong><ul>
<li>Partition<ul>
<li>决定数据由哪个Reducer处理，从而分区（如Hash法）</li>
</ul>
</li>
<li>MemoryBuffer<ul>
<li>内存缓冲区，每个Map的结果和Partition处理的Key Value结果都保存在缓存中</li>
<li>缓冲区大小：默认100M</li>
<li>溢写阈值：100M * 0.8 = 80M</li>
<li>缓冲区中的数据：{partition, key, value}三元组</li>
</ul>
</li>
<li>Spill<ul>
<li>内存缓冲区达到阈值时，溢写Spill线程锁住这80M的缓冲区，开始将数据写到本地磁盘中，然后释放内存</li>
<li>每次溢写都生成一个数据文件</li>
<li>溢出的数据到磁盘前会对数据进行Key排序Sort，以及合并Combiner</li>
<li>发送相同Reduce的Key数量，会拼接到一起，减少Partition的索引数量<ul>
<li>Sort<ul>
<li>缓冲区数据按照Key进行排序</li>
</ul>
</li>
<li>Combiner<ul>
<li>数据合并，相同Key的数据，Value值合并，减少输出传输量</li>
<li>Combiner函数事实上是Reducer函数，满足<strong>Combiner处理不影响{sum, max等}最终Reduce等结果时</strong>，可以极大提升性能</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Reduce<ul>
<li>多个Reduce任务输入的数据都属于不同的Partition，因此结果数据的Key不重复</li>
<li>合并Reduce输出文件即可得到最终的结果</li>
</ul>
</li>
</ul>
<h3 id="配置注意事项"><a href="#配置注意事项" class="headerlink" title="配置注意事项"></a>配置注意事项</h3><ul>
<li>文件句柄个数<ul>
<li>ulimit命令</li>
<li>报错“当前打开文件超出最大个数”时使用</li>
</ul>
</li>
<li>合适的slot<ul>
<li>单机map、reduce个数【相互隔离】</li>
<li><code>mapred.tasktracker.map.tasks.maximum</code>配置Map的slot数（默认2）</li>
<li><code>mapreduce.tasktracker.tasks.reduce.maximum</code>配置Reduce的slot数（默认2）</li>
<li>内存限制</li>
<li>Slot数 = CPU核数 - 1</li>
<li>多机集群分离</li>
</ul>
</li>
<li>磁盘情况<ul>
<li>适合单机多磁盘（Raid阵列）</li>
<li><code>mapred.local.dir</code>Map中间结果存储路径</li>
<li><code>dfs.data.dir</code>HDFS数据存储路径</li>
</ul>
</li>
<li>配置加载<ul>
<li>简单配置通过提交作业时-file分发</li>
<li>复杂较大配置<ul>
<li>传入HDFS</li>
<li>Map中打开文件读取</li>
<li>建立内存结构</li>
</ul>
</li>
</ul>
</li>
<li>确定Map任务数依次优先参考如下几个原则<ul>
<li>每个Map任务使用的内存不超过800M， 尽量在500M以下</li>
<li>每个Map任务运行时间控制在大约20分钟，最好1-3分钟</li>
<li>每个Map任务处理的最大数据量为一个HDFS块大小，一个Map任务处理的输入不能跨文件</li>
<li>Map任务总数不能超过平台可用的任务槽位</li>
</ul>
</li>
<li>Map要点<ul>
<li>Map个数为Split份数</li>
<li>压缩文件不可切分【通常压缩文件用于控制Map个数】</li>
<li>非压缩文件和Sequence文件可以切分</li>
<li><code>dfs.block.size</code>决定block大小</li>
</ul>
</li>
<li>确定Reduce任务数依次优先参考如下几个原则<ul>
<li>每个Reduce任务使用的内存不超过800M， 尽量在500M以下</li>
<li>每个Reduce任务运行时间控制在大约20分钟，最好1-3分钟</li>
<li>整个Reduce阶段的输入数据总量</li>
<li>每个Reduce任务处理的数据量控制在500M以内</li>
<li>Map任务数与Reduce任务数乘积</li>
<li>输出数据要求</li>
</ul>
</li>
<li>Reduce个数设置<ul>
<li><code>mapred.reduce.tasks</code>默认为1</li>
<li>Reduce个数太少<ul>
<li>单次执行慢</li>
<li>出错再试成本高</li>
</ul>
</li>
<li>Reduce个数太大<ul>
<li>Shuffle开销大</li>
<li>输出大量小文件</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://image.alessa0.cn/071824.png" alt="MapReduce"></p>
<h2 id="MapReduce重要进程（HDFS1-0）"><a href="#MapReduce重要进程（HDFS1-0）" class="headerlink" title="MapReduce重要进程（HDFS1.0）"></a>MapReduce重要进程（HDFS1.0）</h2><ul>
<li><p><strong>JobTracker</strong></p>
<ul>
<li>主进程，负责接收客户作业提交，调度任务到作业节点上运行，并提供诸如监控工作节点状态及任务进度等管理功能，1个MapReduce集群有1个JobTracker，一般运行在可靠的硬件上</li>
<li>TaskTracker是通过周期性的心跳来通知JobTracker其当前的健康状态，每一次心跳包含了可用的map和reduce任务数目，占用的数目及运行中任务的详细信息。JobTracker利用一个<strong>线程池</strong>来<strong>同时</strong>处理心跳和客户请求。</li>
<li>等待JobClient提交作业</li>
</ul>
</li>
<li><p><strong>TaskTracker</strong></p>
<ul>
<li>由JobTracker指派任务，实例化用户程序，在本地执行任务并周期性地向JobTracker汇报状态。在每一个工作节点上永远只会有<strong>1个</strong>TaskTracker。</li>
<li>每3s主动向JobTracker发送心跳询问有没有任务，如果有，让其派发任务给它执行</li>
</ul>
</li>
</ul>
<p>MapReduce采用<strong>多进程</strong>并发</p>
<ul>
<li>优点：<ul>
<li>方便任务资源控制和调配</li>
<li>运行稳定</li>
</ul>
</li>
<li>缺点：<ul>
<li>消耗更多的启动时间【不适合低延时作业】</li>
</ul>
</li>
</ul>
<h2 id="MapReduce作业提交流程"><a href="#MapReduce作业提交流程" class="headerlink" title="MapReduce作业提交流程"></a>MapReduce作业提交流程</h2><ol>
<li>客户端Client提交作业请求</li>
<li>Master的JobTracker接收请求分配Job ID</li>
<li>客户端在HDFS对应Job ID目录上传资源</li>
<li>Client向JobTracker正式提交任务</li>
<li>JobTracker对任务进行初始化</li>
<li>JobTracker将HDFS对应Job ID目录文件分发到各个TaskTracker节点</li>
<li>TaskTracker向JobTracker发送心跳</li>
<li>TaskTracker向HDFS分发Job资源</li>
<li>TaskTracker执行任务</li>
</ol>
<h2 id="MapReduce作业调度"><a href="#MapReduce作业调度" class="headerlink" title="MapReduce作业调度"></a>MapReduce作业调度</h2><ul>
<li>默认<strong>先进先出（FIFO）</strong>队列调度模式<ul>
<li>优先级：very_high, high, normal, low, very low</li>
</ul>
</li>
</ul>
<h2 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h2><blockquote>
<p>MapReduce和HDFS采用Java实现，默认提供Java编程接口</p>
<p>Streaming框架允许任何程序语言实现的程序在Hadoop MapReduce中使用</p>
<p>Streaming方便已有程序向Hadoop平台移植</p>
</blockquote>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>开发效率高<ul>
<li>方便移植Hadoop平台，仅需按照一定的格式从标准输入读取数据，向标准输出写数据</li>
<li>原有单机程序稍加改动即可在Hadoop平台进行分布式处理</li>
<li>容易单机调试<ul>
<li><code>cat input | mapper | sort | reducer &gt; output</code></li>
</ul>
</li>
</ul>
</li>
<li>便于平台进行资源控制<ul>
<li>Streaming框架中通过limit等方式可以灵活地限制应用程序使用的内存等资源</li>
</ul>
</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>Streaming默认仅能处理文本数据，如要对二进制数据进行处理，比较好的方法是将二进制的key和value进行base64的编码转换成文本</li>
<li>两次数据拷贝和解析（分割），带来一定开销</li>
</ul>
<h3 id="命令行要点"><a href="#命令行要点" class="headerlink" title="命令行要点"></a>命令行要点</h3><ul>
<li>input<ul>
<li>指定作业的输入文件HDFS路径，支持使用*通配符，支持指定多个文件或目录，可多次使用</li>
</ul>
</li>
<li>output<ul>
<li>指定作业的输出文件HDFS路径，路径必须不存在，并且执行作业用户需要具备创建该目录的权限，只能使用一次</li>
</ul>
</li>
<li>mapper<ul>
<li>用户自己写的Map程序</li>
</ul>
</li>
<li>reducer<ul>
<li>用户自己写的Reduce程序</li>
</ul>
</li>
<li>file<ul>
<li>打包本地文件到提交的Job中<ul>
<li>map和reduce的执行文件</li>
<li>map和reduce要用输入的文件，如配置文件</li>
</ul>
</li>
<li>类似的配置还有<ul>
<li>cacheFile 提交HDFS文件到提交的Job中</li>
<li>cacheArchive 提交HDFS压缩文件到提交的Job中</li>
</ul>
</li>
</ul>
</li>
<li>jobconf<ul>
<li>提交作业的一些配置属性</li>
<li>常见配置<ul>
<li><code>mapred.map.tasks</code>map task数目</li>
<li><code>mapred.reduce.tasks</code>reduce task数目</li>
<li><code>stream.num.map.output.key.field</code>指定map task输出记录中key所占的域数目</li>
<li><code>num.key.dields.for.partition</code>指定对key分出来的前几部分做partition而不是整个key</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="HDFS1-0"><a href="#HDFS1-0" class="headerlink" title="HDFS1.0"></a>HDFS1.0</h1><h2 id="HDFS1-0基础"><a href="#HDFS1-0基础" class="headerlink" title="HDFS1.0基础"></a>HDFS1.0基础</h2><ul>
<li>HDFS1.0系统架构<ul>
<li>Master<ul>
<li>NameNode<ul>
<li>管理着文件系统命名空间<ul>
<li>维护着文件系统树及树中的所有文件和目录</li>
</ul>
</li>
<li>存储元数据<ul>
<li>NameNode保存元信息的种类<ul>
<li>文件名目录名及它们之间的层级关系</li>
<li>文件目录的所有者及其权限</li>
<li>每个文件块的名及文件有哪些块组成</li>
</ul>
</li>
</ul>
</li>
<li><strong>元数据保存在内存中</strong><ul>
<li>NameNode元信息并不包含每个块的位置信息</li>
</ul>
</li>
<li>保存文件/Block/DataNode之间的<strong>映射</strong>关系<ul>
<li>文件名 -&gt; Block</li>
<li>Block -&gt; DataNode</li>
</ul>
</li>
<li>运行NameNode会占用大量内存和I/O资源，一般NameNode不会存储用户数据或执行MapReduce任务</li>
<li>全Hadoop系统仅一个NameNode<ul>
<li>单点问题<ul>
<li>方案1：将Hadoop元数据写入到本地文件系统时同步到远程挂载的网络文件系统NFS</li>
<li>方案2：运行SecondaryNameNode进程，持久化到磁盘</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>SecondaryNameNode<ul>
<li><strong>并不是NameNode</strong>，不取代NameNode也不是NameNode的备份</li>
<li>作用是与NameNode交互，定期通过编辑日志文件合并命名空间镜像</li>
<li>当NameNode发生故障，NameNode会通过自己合并的命名空间镜像副本来恢复数据</li>
<li>SecondaryNameNode保存的NameNode元信息总是<strong>滞后于NameNode</strong>的，会导致部分数据丢失</li>
</ul>
</li>
</ul>
</li>
<li>Worker<ul>
<li>DataNode<ul>
<li>保存Block -&gt; Path的映射关系</li>
<li>负责存储数据块，负责为系统客户端提供数据块的读写服务</li>
<li>根据NameNode的指示进行创建/删除和复制等操作</li>
<li>心跳机制，定期报告文件块列表信息</li>
<li>DataNode间通信，进行块的副本处理<ul>
<li>数据块<ul>
<li>HDFS默认数据块大小为64M</li>
<li>磁盘块一般为512B</li>
<li>块增大可以减少寻址时间，降低寻址时间/文件传输时间</li>
<li>数据块过大导致整体任务量过小，降低作业处理速度</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Hadoop更倾向存储大文件<ul>
<li>一般来说，一条元信息记录会占用200byte内存空间。</li>
<li>假设块大小为64M，备份数量是3，那么一个1G大小的文件将占用16 * 3 = 48 个文件块</li>
<li>如现在有1000个1M大小的文件，则会占用 1000 * 3 = 3000 个文件块（多个文件不能放到一个块中）</li>
<li>如果文件越小，存储同等大小的文件所需要的元信息就越多</li>
</ul>
</li>
<li>元信息持久化<ul>
<li>在NameNode中存放元信息的文件是fsimage</li>
<li>在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个文件edits中</li>
<li>fsimage文件与edits文件会被SecondaryNameNode进程周期性合并</li>
</ul>
</li>
</ul>
<p><img src="https://image.alessa0.cn/141922.png" alt="SecondaryNameNode"></p>
<h2 id="机架感知策略"><a href="#机架感知策略" class="headerlink" title="机架感知策略"></a>机架感知策略</h2><blockquote>
<p>默认3副本</p>
</blockquote>
<ul>
<li>第一个副本，放在与客户端相同的节点（如客户端是集群外的一台机器，就随机算节点，但是系统会避免挑选太满或太忙的节点）</li>
<li>第二个副本，放在不同机架（随机选择）的节点</li>
<li>第三个副本，放在与第二个副本同机架但是不同节点上</li>
<li>distance<ul>
<li>distance = 0, 相同DataNode</li>
<li>distance = 2, 相同Rack下的不同DataNode</li>
<li>distance = 4, 相同IDC下的不同DataNode</li>
<li>distance = 6, 不同IDC下的DataNode</li>
</ul>
</li>
</ul>
<h2 id="数据完整性校验"><a href="#数据完整性校验" class="headerlink" title="数据完整性校验"></a>数据完整性校验</h2><ul>
<li><p>不希望在存储和处理数据时丢失或损坏任何数据</p>
</li>
<li><p>HDFS会对写入的数据计算校验和，并在读取时验证校验和</p>
</li>
<li><p>两种校验方法</p>
<ul>
<li><p>校验和</p>
<ul>
<li>检测损坏数据的常用方法时在第一次写入系统时计算数据的校验和，在通道传输过程中，如果新生成的校验和不完全匹配原始的校验和，那么数据就会被认定为是被损坏的（<strong>默认512字节创建1个校验码</strong>）</li>
</ul>
</li>
<li><p>数据块检测程序DataBlockScanner</p>
<ul>
<li>在DataNode节点上开启一个后台进程，来定期验证存储在它上的所有块，这个是防止物理介质出现损减情况而造成的数据损坏（损坏数据从其他DataNode拷贝）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="可靠性措施"><a href="#可靠性措施" class="headerlink" title="可靠性措施"></a>可靠性措施</h2><ul>
<li>一个名字节点和多个数据节点</li>
<li>数据复制（冗余机制）<ul>
<li>存放位置（机架感知策略）</li>
<li>并不是3副本写完才返回ack，三副本中有1个写成功就返回ack</li>
</ul>
</li>
<li>故障检测<ul>
<li>数据节点<ul>
<li>心跳包（检测是否宕机）</li>
<li>块报告（安全模式下检测）</li>
<li>数据完整性检测（校验和比较）</li>
</ul>
</li>
<li>名字节点<ul>
<li>日志文件</li>
<li>镜像文件</li>
</ul>
</li>
</ul>
</li>
<li>空间回收机制<ul>
<li>Trash目录（修改core-site.xml）</li>
</ul>
</li>
</ul>
<h2 id="HDFS-amp-MapReduce本地模式"><a href="#HDFS-amp-MapReduce本地模式" class="headerlink" title="HDFS&amp;MapReduce本地模式"></a>HDFS&amp;MapReduce本地模式</h2><ul>
<li>Master（小集群）<ul>
<li>NameNode</li>
<li>JobTracker</li>
</ul>
</li>
<li>Slave<ul>
<li>DataNode</li>
<li>TaskTracker</li>
</ul>
</li>
</ul>
<h1 id="案例代码"><a href="#案例代码" class="headerlink" title="案例代码"></a>案例代码</h1><blockquote>
<p>常见实践有：</p>
<blockquote>
<p>数据统计</p>
<blockquote>
<p>WordCount</p>
</blockquote>
<p>数据过滤（清洗）</p>
<blockquote>
<p>从日志查找某一个条件等数据</p>
<p>除去非法数据，保留合法数据</p>
<p>数据格式整理</p>
</blockquote>
<p>同类汇聚</p>
<blockquote>
<p>多份日志，相同时间点、用户行为日志Join</p>
<p>类表格文件存储中，相同主键拼接相关属性</p>
<p>历史的主数据与新增，修改数据合并</p>
</blockquote>
<p>全局排序</p>
<blockquote>
<p>混合日志，按时间排列好顺序</p>
<p>按某个或多个字段有序</p>
</blockquote>
<p>容错框架</p>
<blockquote>
<p>测试集群状态：在集群上运行一个错误代码Job，进行观察</p>
<p>使用易出错的服务，365 * 24 运行</p>
<p>计算规模经常变化调整的服务</p>
<p>单进程程序，迅速提升执行计算效率</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h2><h3 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-py"><a href="#map-py" class="headerlink" title="map.py"></a>map.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> ss:</span><br><span class="line">        <span class="built_in">print</span>(word.strip() + <span class="string">&#x27;\t&#x27;</span> + <span class="string">&#x27;1&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="reduce-py"><a href="#reduce-py" class="headerlink" title="reduce.py"></a>reduce.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    word, cnt = ss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line">    <span class="keyword">if</span> current_word != word:</span><br><span class="line">        <span class="built_in">print</span>(current_word.strip() + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line">        current_word = word</span><br><span class="line">        cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    cnt_sum += <span class="built_in">int</span>(cnt)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(current_word.strip() + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="The-Man-of-Property-txt"><a href="#The-Man-of-Property-txt" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></table></figure>

<h4 id="run-sh"><a href="#run-sh" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop命令地址</span></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop streaming jar包地址</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输入文件路径</span></span><br><span class="line">INPUT_FILE_PATH=<span class="string">&quot;/week01/01_mr_wordcount/The_Man_of_Property.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输出文件路径</span></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/01_mr_wordcount/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入文件本地路径</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">&quot;/mnt/hgfs/Code/week01/01_mr_wordcount/The_Man_of_Property.txt&quot;</span></span><br><span class="line"><span class="comment"># 输入文件 HDFS上传路径</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/01_mr_wordcount&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除HDFS存在目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建HDFS 上传目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="comment"># 将本地输入文件上传到HDFS目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map.py&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red.py&quot;</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># -file 过时了，2.8.5用-files代替，作为可选参数需放在-input等参数前面</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<h2 id="AllSort-1Reduce"><a href="#AllSort-1Reduce" class="headerlink" title="AllSort_1Reduce"></a>AllSort_1Reduce</h2><h3 id="Version-1"><a href="#Version-1" class="headerlink" title="Version 1"></a>Version 1</h3><h4 id="Python3-1"><a href="#Python3-1" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-sort-py"><a href="#map-sort-py" class="headerlink" title="map_sort.py"></a>map_sort.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + <span class="built_in">int</span>(key)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">str</span>(new_key) + <span class="string">&#x27;\t&#x27;</span> + val)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="red-sort-py"><a href="#red-sort-py" class="headerlink" title="red_sort.py"></a>red_sort.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    new_key, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    key = <span class="built_in">int</span>(new_key) - base_count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s\t%s&#x27;</span> % (key, val))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="a-txt"><a href="#a-txt" class="headerlink" title="a.txt"></a>a.txt</h5><figure class="highlight"><table><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></table></figure>

<h5 id="b-txt"><a href="#b-txt" class="headerlink" title="b.txt"></a>b.txt</h5><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></table></figure>


<h5 id="run-sh-1"><a href="#run-sh-1" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">&quot;/week01/02_mr_allsort_1reduce/a.txt&quot;</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">&quot;/week01/02_mr_allsort_1reduce/b.txt&quot;</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/02_mr_allsort_1reduce/version1/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/02_mr_allsort_1reduce/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map_sort.py&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red_sort.py&quot;</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 依赖MapReduce框架自身的sort功能：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1</span></span><br><span class="line">    <span class="comment"># -jobconf 可用-D 替代，作为可选参数放在-input等前面</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h3 id="Version-2"><a href="#Version-2" class="headerlink" title="Version 2"></a>Version 2</h3><h4 id="Python3-2"><a href="#Python3-2" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-sort-py-1"><a href="#map-sort-py-1" class="headerlink" title="map_sort.py"></a>map_sort.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="built_in">print</span>(line.strip())</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h5 id="red-sort-py-1"><a href="#red-sort-py-1" class="headerlink" title="red_sort.py"></a>red_sort.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="built_in">print</span>(line.strip())</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h5 id="a-txt-1"><a href="#a-txt-1" class="headerlink" title="a.txt"></a>a.txt</h5><figure class="highlight"><table><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></table></figure>

<h5 id="b-txt-1"><a href="#b-txt-1" class="headerlink" title="b.txt"></a>b.txt</h5><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></table></figure>


<h5 id="run-sh-2"><a href="#run-sh-2" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">&quot;/week01/02_mr_allsort_1reduce/a.txt&quot;</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">&quot;/week01/02_mr_allsort_1reduce/b.txt&quot;</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/02_mr_allsort_1reduce/version2/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/02_mr_allsort_1reduce/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span><br><span class="line">    -D stream.num.map.output.key.fields=1 \</span><br><span class="line">    -D mapreduce.partition.keypartitioner.options=<span class="string">&quot;-k1,1&quot;</span> \</span><br><span class="line">    -D mapreduce.partition.keycomparator.options=<span class="string">&quot;-k1,1n&quot;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map_sort.py&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red_sort.py&quot;</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置单reduce：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1 \</span></span><br><span class="line">    <span class="comment"># 控制分发，完成二次排序：</span></span><br><span class="line">    <span class="comment"># -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span></span><br><span class="line">    <span class="comment"># 完成key排序：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=1 \</span></span><br><span class="line">    <span class="comment"># 选择哪一部分做partition，-k1,1表示partition的key范围是（1，1），即第1列</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options=&quot;-k1,1&quot; \</span></span><br><span class="line">    <span class="comment"># 设置key中需要比较的字段或字节范围，-k1,1表示sort的key范围是（1，1），即第1列，n表示按数字number类型排序</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keycomparator.options=&quot;-k1,1n&quot; \</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="AllSort"><a href="#AllSort" class="headerlink" title="AllSort"></a>AllSort</h2><h3 id="Python3-3"><a href="#Python3-3" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-sort-py-2"><a href="#map-sort-py-2" class="headerlink" title="map_sort.py"></a>map_sort.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + <span class="built_in">int</span>(key)</span><br><span class="line"></span><br><span class="line">    partition_index = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> new_key &lt; (<span class="number">10100</span> + <span class="number">10000</span>) / <span class="number">2</span>:</span><br><span class="line">        partition_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s\t%s&quot;</span> % (partition_index, new_key, val))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h4 id="red-sort-py-2"><a href="#red-sort-py-2" class="headerlink" title="red_sort.py"></a>red_sort.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    partition_index, new_key, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    key = <span class="built_in">int</span>(new_key) - base_count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\t&#x27;</span>.join([<span class="built_in">str</span>(key), val]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="a-txt-2"><a href="#a-txt-2" class="headerlink" title="a.txt"></a>a.txt</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">1	hadoop</span><br><span class="line">3	hadoop</span><br><span class="line">5	hadoop</span><br><span class="line">7	hadoop</span><br><span class="line">9	hadoop</span><br></pre></td></tr></table></figure>

<h4 id="b-txt-2"><a href="#b-txt-2" class="headerlink" title="b.txt"></a>b.txt</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">2</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">4</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">6</span>	<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span><span class="number">8</span>	<span class="keyword">java</span></span><br></pre></td></tr></table></figure>

<h4 id="run-sh-3"><a href="#run-sh-3" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">&quot;/week01/03_mr_allsort/a.txt&quot;</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">&quot;/week01/03_mr_allsort/b.txt&quot;</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/03_mr_allsort/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/03_mr_allsort/a.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/03_mr_allsort/b.txt&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/03_mr_allsort/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map_sort.py&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red_sort.py&quot;</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value，此处以前2列为key</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=2 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（仅能从头顺序选取范围）用来做分发，此处以第1列做partition</span></span><br><span class="line">    <span class="comment"># -D num.key.fields.for.partition=1 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（可选择中间范围）用来做分发</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options=&quot;-k1,1&quot; \</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="File-Broadcast"><a href="#File-Broadcast" class="headerlink" title="File_Broadcast"></a>File_Broadcast</h2><h3 id="File"><a href="#File" class="headerlink" title="File"></a>File</h3><h4 id="Python3-4"><a href="#Python3-4" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-1"><a href="#map-py-1" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="red-py"><a href="#red-py" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="The-Man-of-Property-txt-1"><a href="#The-Man-of-Property-txt-1" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></table></figure>

<h5 id="white-list"><a href="#white-list" class="headerlink" title="white_list"></a>white_list</h5><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure>

<h5 id="run-sh-4"><a href="#run-sh-4" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/file/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">&quot;/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -files map.py,red.py,white_list \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map.py mapper_func white_list&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red.py reducer_func&quot;</span> \</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="cacheFile"><a href="#cacheFile" class="headerlink" title="cacheFile"></a>cacheFile</h3><h4 id="Python3-5"><a href="#Python3-5" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-2"><a href="#map-py-2" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">file</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    file_in = <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="red-py-1"><a href="#red-py-1" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        word, cnt = ss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="built_in">print</span>(current_word.strip() + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        cnt_sum += <span class="built_in">int</span>(cnt)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(current_word.strip() + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(cnt_sum))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="The-Man-of-Property-txt-2"><a href="#The-Man-of-Property-txt-2" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></table></figure>

<h5 id="white-list-1"><a href="#white-list-1" class="headerlink" title="white_list"></a>white_list</h5><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure>

<h5 id="run-sh-5"><a href="#run-sh-5" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/cachefile/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/04_mr_file_broadcast/white_list&quot;</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">&quot;/week01/04_mr_file_broadcast/&quot;</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">&quot;/week01/04_mr_file_broadcast/cachefile/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachefile_demo \</span><br><span class="line">    -files map.py,red.py,<span class="string">&quot;hdfs://master:9000/week01/04_mr_file_broadcast/cachefile/white_list#WH&quot;</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map.py mapper_func WH&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red.py reducer_func&quot;</span> \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 过时了</span></span><br><span class="line">    <span class="comment"># -cacheFile &quot;hdfs://master:9000/week01/04_mr_file_broadcast/cachefile</span></span><br><span class="line">    <span class="comment"># /white_list#WWWHHH&quot; \</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#-cacheFile &quot;$&#123;HDFS_FILE_PATH&#125;#WH&quot; \</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="cacheArchive"><a href="#cacheArchive" class="headerlink" title="cacheArchive"></a>cacheArchive</h3><h4 id="Python3-6"><a href="#Python3-6" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-3"><a href="#map-py-3" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span>(<span class="params">f</span>):</span></span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span>(<span class="params">f</span>):</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">&#x27;/&#x27;</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="red-py-2"><a href="#red-py-2" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="The-Man-of-Property-txt-3"><a href="#The-Man-of-Property-txt-3" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></table></figure>

<h5 id="w-tar-gz"><a href="#w-tar-gz" class="headerlink" title="w.tar.gz"></a>w.tar.gz</h5><h6 id="white-list-1"><a href="#white-list-1" class="headerlink" title="white_list_1"></a>white_list_1</h6><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure>

<h6 id="white-list-2"><a href="#white-list-2" class="headerlink" title="white_list_2"></a>white_list_2</h6><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">a</span></span><br></pre></td></tr></table></figure>


<h5 id="run-sh-6"><a href="#run-sh-6" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/04_mr_file_broadcast/cachearchive/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/04_mr_file_broadcast/w.tar.gz&quot;</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">&quot;/week01/04_mr_file_broadcast/&quot;</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">&quot;/week01/04_mr_file_broadcast/cachearchive/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachearchive_demo \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">&quot;hdfs://master:9000/week01/04_mr_file_broadcast/cachearchive/w.tar.gz#WH.gz&quot;</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map.py mapper_func WH.gz&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red.py reducer_func&quot;</span> \</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><h3 id="Python3-7"><a href="#Python3-7" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-py-4"><a href="#map-py-4" class="headerlink" title="map.py"></a>map.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span>(<span class="params">f</span>):</span></span><br><span class="line">    file_in = <span class="built_in">open</span>(f, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span>(<span class="params">f</span>):</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">&#x27;/&#x27;</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span>(<span class="params">f</span>):</span></span><br><span class="line">    word_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span>(<span class="params">white_list_fd</span>):</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="red-py-3"><a href="#red-py-3" class="headerlink" title="red.py"></a>red.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span>():</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                <span class="built_in">sum</span> += count</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">sum</span>))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(<span class="built_in">int</span>(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        <span class="built_in">sum</span> += count</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t%s&quot;</span> % (current_word, <span class="built_in">str</span>(<span class="built_in">sum</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = <span class="built_in">getattr</span>(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="The-Man-of-Property-txt-4"><a href="#The-Man-of-Property-txt-4" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h4><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">“The Forsyte Saga” was the title originally destined <span class="keyword">for</span> that part <span class="keyword">of</span> it which <span class="keyword">is</span> <span class="keyword">called</span> “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt it <span class="keyword">for</span> the collected chronicles <span class="keyword">of</span> the Forsyte <span class="keyword">family</span> has indulged the Forsytean tenacity that <span class="keyword">is</span> <span class="keyword">in</span> <span class="keyword">all</span> <span class="keyword">of</span> us. The word Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> the ground that it connotes the heroic <span class="keyword">and</span> that there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But it <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> <span class="keyword">all</span>, this long tale, though it may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> the essential heat <span class="keyword">of</span> <span class="keyword">conflict</span>. Discounting <span class="keyword">for</span> the gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> <span class="built_in">old</span> days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, the folk <span class="keyword">of</span> the <span class="built_in">old</span> Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof against the inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. <span class="keyword">And</span> <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days that never were, seem <span class="keyword">to</span> startle <span class="keyword">out</span> <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> the Victorian era, we may be sure that tribal instinct was even <span class="keyword">then</span> the prime force, <span class="keyword">and</span> that “<span class="keyword">family</span>” <span class="keyword">and</span> the sense <span class="keyword">of</span> home <span class="keyword">and</span> property counted <span class="keyword">as</span> they <span class="keyword">do</span> <span class="keyword">to</span> this day, <span class="keyword">for</span> <span class="keyword">all</span> the recent efforts <span class="keyword">to</span> “talk them <span class="keyword">out</span>.”</span><br></pre></td></tr></table></figure>

<h4 id="white-list-dir-tar-gz"><a href="#white-list-dir-tar-gz" class="headerlink" title="white_list_dir.tar.gz"></a>white_list_dir.tar.gz</h4><h5 id="white-list-1-1"><a href="#white-list-1-1" class="headerlink" title="white_list_1"></a>white_list_1</h5><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure>

<h5 id="white-list-2-1"><a href="#white-list-2-1" class="headerlink" title="white_list_2"></a>white_list_2</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">a</span></span><br></pre></td></tr></table></figure>

<h4 id="run-sh-7"><a href="#run-sh-7" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">&quot;/week01/05_mr_compression/The_Man_of_Property.txt&quot;</span></span><br><span class="line">OUTPUT_PATH=<span class="string">&quot;/week01/05_mr_compression/run_1/output/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/05_mr_compression/The_Man_of_Property.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/05_mr_compression/white_list_dir.tar.gz&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/05_mr_compression/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=compression_run_1_demo \</span><br><span class="line">    -D mapreduce.map.output.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">&quot;hdfs://master:9000/week01/05_mr_compression/white_list_dir.tar.gz#WH.gz&quot;</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map.py mapper_func WH.gz&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red.py reducer_func&quot;</span> \</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h2><h3 id="Python3-8"><a href="#Python3-8" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-a-py"><a href="#map-a-py" class="headerlink" title="map_a.py"></a>map_a.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">&#x27;	&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t1\t%s&quot;</span> % (key, val))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h4 id="a-txt-3"><a href="#a-txt-3" class="headerlink" title="a.txt"></a>a.txt</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">aaa1</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa2</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa3</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa4</span>	<span class="number">123</span></span><br><span class="line"><span class="attribute">aaa5</span>	<span class="number">123</span></span><br></pre></td></tr></table></figure>

<h4 id="map-b-py"><a href="#map-b-py" class="headerlink" title="map_b.py"></a>map_b.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">&#x27;	&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s\t2\t%s&quot;</span> % (key, val))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h4 id="b-txt-3"><a href="#b-txt-3" class="headerlink" title="b.txt"></a>b.txt</h4><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">aaa1</span>	hadoop</span><br><span class="line">aaa2	hadoop</span><br><span class="line">aaa3	hadoop</span><br><span class="line">aaa4	hadoop</span><br><span class="line">aaa5	hadoop</span><br></pre></td></tr></table></figure>

<h4 id="red-join-py"><a href="#red-join-py" class="headerlink" title="red_join.py"></a>red_join.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val_1 = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, flag, val = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">        val_1 = val</span><br><span class="line">    <span class="keyword">elif</span> flag == <span class="string">&#x27;2&#x27;</span>:</span><br><span class="line">        val_2 = val</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%s\t%s\t%s&quot;</span> % (key, val_1, val_2))</span><br><span class="line">        val_1 = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="run-sh-8"><a href="#run-sh-8" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/bin/hadoop&quot;</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">&quot;/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar&quot;</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">&quot;/week01/06_mr_join/a.txt&quot;</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">&quot;/week01/06_mr_join/b.txt&quot;</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_A=<span class="string">&quot;/week01/06_mr_join/output/a/python3&quot;</span></span><br><span class="line">OUTPUT_PATH_B=<span class="string">&quot;/week01/06_mr_join/output/b/python3&quot;</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_JOIN=<span class="string">&quot;/week01/06_mr_join/output/join/python3&quot;</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">&quot;/mnt/hgfs/Code/week01/06_mr_join/a.txt&quot;</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">&quot;/mnt/hgfs/Code/week01/06_mr_join/b.txt&quot;</span></span><br><span class="line">UPLOAD_PATH=<span class="string">&quot;/week01/06_mr_join/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span> <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_JOIN&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map_a.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map_a.py&quot;</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map_b.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;python map_b.py&quot;</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files red_join.py \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span>,<span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_JOIN&#125;</span> \</span><br><span class="line">    -mapper <span class="string">&quot;cat&quot;</span> \</span><br><span class="line">    -reducer <span class="string">&quot;python red_join.py&quot;</span> \</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="附加项目：pyweb"><a href="#附加项目：pyweb" class="headerlink" title="附加项目：pyweb"></a>附加项目：pyweb</h2><h3 id="Python3-9"><a href="#Python3-9" class="headerlink" title="Python3"></a>Python3</h3><p><strong>首先</strong>请确保使用<code>pip install web.py==0.40-dev1</code></p>
<h4 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> web</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">urls = (</span><br><span class="line">    <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;index&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;/test&#x27;</span>, <span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">app = web.application(urls, <span class="built_in">globals</span>())</span><br><span class="line"></span><br><span class="line">userid_rec_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;file.test&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">        ss = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        userid = ss[<span class="number">0</span>].strip()</span><br><span class="line">        items = ss[<span class="number">1</span>].strip()</span><br><span class="line">        userid_rec_dict[userid] = items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">index</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span>(<span class="params">self</span>):</span></span><br><span class="line">        params = web.<span class="built_in">input</span>()</span><br><span class="line">        userid = params.get(<span class="string">&#x27;userid&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> userid <span class="keyword">not</span> <span class="keyword">in</span> userid_rec_dict:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;no rec!&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;\n&#x27;</span>.join(userid_rec_dict[userid].strip().split(<span class="string">&#x27;&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(web.<span class="built_in">input</span>())</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;222&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app.run()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="file-test"><a href="#file-test" class="headerlink" title="file.test"></a>file.test</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">zhangsan</span>	<span class="number">1</span></span><br><span class="line"><span class="attribute">lisi</span>	<span class="number">2</span></span><br><span class="line"><span class="attribute">wangwu</span>	<span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>在<strong>终端</strong>输入<code>python main.py 12345 </code>启动web服务器</p>
<ul>
<li><p>如遇到报错信息</p>
</li>
<li><p>```<br>Traceback (most recent call last):<br>  File “D:\Program Files\Python\Python37\lib\site-packages\web\utils.py”, line 526, in take</p>
<pre><code>yield next(seq)
</code></pre>
<p>StopIteration<br>The above exception was the direct cause of the following exception:<br>Traceback (most recent call last):<br>  File “D:\Python\hello.py”, line 6, in <module></p>
<pre><code>app = web.application(urls, globals(),True)
</code></pre>
<p>  File “D:\Program Files\Python\Python37\lib\site-packages\web\application.py”, line 62, in <strong>init</strong></p>
<pre><code>self.init_mapping(mapping)
</code></pre>
<p>  File “D:\Program Files\Python\Python37\lib\site-packages\web\application.py”, line 130, in init_mapping</p>
<pre><code>self.mapping = list(utils.group(mapping, 2))
</code></pre>
<p>  File “D:\Program Files\Python\Python37\lib\site-packages\web\utils.py”, line 531, in group</p>
<pre><code>x = list(take(seq, size))
</code></pre>
<p>RuntimeError: generator raised StopIteration</p>
<figure class="highlight nim"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">修改<span class="type">Lib</span>\site-packages\web 下的utils.py文件</span><br><span class="line"></span><br><span class="line">```diff</span><br><span class="line">+ <span class="keyword">try</span>:</span><br><span class="line">      <span class="keyword">yield</span> next(<span class="built_in">seq</span>) <span class="comment"># 526行</span></span><br><span class="line">+ <span class="keyword">except</span> <span class="type">StopIteration</span>:</span><br><span class="line">+     <span class="keyword">return</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>在<strong>网页</strong>打开<code>http://0.0.0.0:12345/</code>即可访问页面</p>
<p>输入<strong>网址</strong><code>http://0.0.0.0:12345/?userid=zhangsan</code>页面显示<strong>1</strong></p>
<p>未来可拓展推荐系统 远程分词服务等</p>
<br />

<p><meting-js
    id="506092035"
    server="netease"
    type="song"
    preload="none"/></p>
<hr />

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/BigData/" rel="tag"># BigData</a>
              <a href="/tags/HDFS1-0/" rel="tag"># HDFS1.0</a>
              <a href="/tags/MapReduce/" rel="tag"># MapReduce</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/BigData%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B000:%E5%B8%B8%E8%A7%81%E4%B8%9A%E5%8A%A1/" rel="prev" title="BigData复习笔记00：系统架构与常见业务">
      <i class="fa fa-chevron-left"></i> BigData复习笔记00：系统架构与常见业务
    </a></div>
      <div class="post-nav-item">
    <a href="/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/BigData%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B002:TFIDF,LCS%E4%B8%8E%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/" rel="next" title="BigData复习笔记02：TFIDF, LCS与中文分词">
      BigData复习笔记02：TFIDF, LCS与中文分词 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%B5%81%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF"><span class="nav-number">1.</span> <span class="nav-text">海量数据分流处理技术</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9FHash%E6%96%B9%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">传统Hash方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%92%E5%88%86"><span class="nav-number">1.2.</span> <span class="nav-text">随机划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7Hash"><span class="nav-number">1.3.</span> <span class="nav-text">一致性Hash</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MapReduce"><span class="nav-number">2.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E6%8F%90%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">前提：分布式存储架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="nav-number">2.2.</span> <span class="nav-text">MapReduce基本思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><span class="nav-number">2.3.</span> <span class="nav-text">MapReduce计算流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.3.1.</span> <span class="nav-text">步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.3.2.</span> <span class="nav-text">详解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="nav-number">2.3.3.</span> <span class="nav-text">配置注意事项</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E9%87%8D%E8%A6%81%E8%BF%9B%E7%A8%8B%EF%BC%88HDFS1-0%EF%BC%89"><span class="nav-number">2.4.</span> <span class="nav-text">MapReduce重要进程（HDFS1.0）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">2.5.</span> <span class="nav-text">MapReduce作业提交流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6"><span class="nav-number">2.6.</span> <span class="nav-text">MapReduce作业调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Streaming"><span class="nav-number">2.7.</span> <span class="nav-text">Streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">2.7.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">2.7.2.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A6%81%E7%82%B9"><span class="nav-number">2.7.3.</span> <span class="nav-text">命令行要点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS1-0"><span class="nav-number">3.</span> <span class="nav-text">HDFS1.0</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS1-0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.1.</span> <span class="nav-text">HDFS1.0基础</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.</span> <span class="nav-text">机架感知策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E6%A0%A1%E9%AA%8C"><span class="nav-number">3.3.</span> <span class="nav-text">数据完整性校验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%8E%AA%E6%96%BD"><span class="nav-number">3.4.</span> <span class="nav-text">可靠性措施</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-amp-MapReduce%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.5.</span> <span class="nav-text">HDFS&amp;MapReduce本地模式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">4.</span> <span class="nav-text">案例代码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#WordCount"><span class="nav-number">4.1.</span> <span class="nav-text">WordCount</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Python3"><span class="nav-number">4.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map-py"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#reduce-py"><span class="nav-number">4.1.1.2.</span> <span class="nav-text">reduce.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Man-of-Property-txt"><span class="nav-number">4.1.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-sh"><span class="nav-number">4.1.1.4.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AllSort-1Reduce"><span class="nav-number">4.2.</span> <span class="nav-text">AllSort_1Reduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Version-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">Version 1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python3-1"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map-sort-py"><span class="nav-number">4.2.1.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red-sort-py"><span class="nav-number">4.2.1.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#a-txt"><span class="nav-number">4.2.1.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#b-txt"><span class="nav-number">4.2.1.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-sh-1"><span class="nav-number">4.2.1.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Version-2"><span class="nav-number">4.2.2.</span> <span class="nav-text">Version 2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python3-2"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map-sort-py-1"><span class="nav-number">4.2.2.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red-sort-py-1"><span class="nav-number">4.2.2.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#a-txt-1"><span class="nav-number">4.2.2.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#b-txt-1"><span class="nav-number">4.2.2.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-sh-2"><span class="nav-number">4.2.2.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AllSort"><span class="nav-number">4.3.</span> <span class="nav-text">AllSort</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Python3-3"><span class="nav-number">4.3.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map-sort-py-2"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">map_sort.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red-sort-py-2"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">red_sort.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#a-txt-2"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#b-txt-2"><span class="nav-number">4.3.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-sh-3"><span class="nav-number">4.3.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#File-Broadcast"><span class="nav-number">4.4.</span> <span class="nav-text">File_Broadcast</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#File"><span class="nav-number">4.4.1.</span> <span class="nav-text">File</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python3-4"><span class="nav-number">4.4.1.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map-py-1"><span class="nav-number">4.4.1.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red-py"><span class="nav-number">4.4.1.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#The-Man-of-Property-txt-1"><span class="nav-number">4.4.1.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white-list"><span class="nav-number">4.4.1.1.4.</span> <span class="nav-text">white_list</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-sh-4"><span class="nav-number">4.4.1.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cacheFile"><span class="nav-number">4.4.2.</span> <span class="nav-text">cacheFile</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python3-5"><span class="nav-number">4.4.2.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map-py-2"><span class="nav-number">4.4.2.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red-py-1"><span class="nav-number">4.4.2.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#The-Man-of-Property-txt-2"><span class="nav-number">4.4.2.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white-list-1"><span class="nav-number">4.4.2.1.4.</span> <span class="nav-text">white_list</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-sh-5"><span class="nav-number">4.4.2.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cacheArchive"><span class="nav-number">4.4.3.</span> <span class="nav-text">cacheArchive</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python3-6"><span class="nav-number">4.4.3.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#map-py-3"><span class="nav-number">4.4.3.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#red-py-2"><span class="nav-number">4.4.3.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#The-Man-of-Property-txt-3"><span class="nav-number">4.4.3.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#w-tar-gz"><span class="nav-number">4.4.3.1.4.</span> <span class="nav-text">w.tar.gz</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#white-list-1"><span class="nav-number">4.4.3.1.4.1.</span> <span class="nav-text">white_list_1</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#white-list-2"><span class="nav-number">4.4.3.1.4.2.</span> <span class="nav-text">white_list_2</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#run-sh-6"><span class="nav-number">4.4.3.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compression"><span class="nav-number">4.5.</span> <span class="nav-text">Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Python3-7"><span class="nav-number">4.5.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map-py-4"><span class="nav-number">4.5.1.1.</span> <span class="nav-text">map.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red-py-3"><span class="nav-number">4.5.1.2.</span> <span class="nav-text">red.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Man-of-Property-txt-4"><span class="nav-number">4.5.1.3.</span> <span class="nav-text">The_Man_of_Property.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#white-list-dir-tar-gz"><span class="nav-number">4.5.1.4.</span> <span class="nav-text">white_list_dir.tar.gz</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#white-list-1-1"><span class="nav-number">4.5.1.4.1.</span> <span class="nav-text">white_list_1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#white-list-2-1"><span class="nav-number">4.5.1.4.2.</span> <span class="nav-text">white_list_2</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-sh-7"><span class="nav-number">4.5.1.5.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Join"><span class="nav-number">4.6.</span> <span class="nav-text">Join</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Python3-8"><span class="nav-number">4.6.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map-a-py"><span class="nav-number">4.6.1.1.</span> <span class="nav-text">map_a.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#a-txt-3"><span class="nav-number">4.6.1.2.</span> <span class="nav-text">a.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#map-b-py"><span class="nav-number">4.6.1.3.</span> <span class="nav-text">map_b.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#b-txt-3"><span class="nav-number">4.6.1.4.</span> <span class="nav-text">b.txt</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#red-join-py"><span class="nav-number">4.6.1.5.</span> <span class="nav-text">red_join.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#run-sh-8"><span class="nav-number">4.6.1.6.</span> <span class="nav-text">run.sh</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%8A%A0%E9%A1%B9%E7%9B%AE%EF%BC%9Apyweb"><span class="nav-number">4.7.</span> <span class="nav-text">附加项目：pyweb</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Python3-9"><span class="nav-number">4.7.1.</span> <span class="nav-text">Python3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#main-py"><span class="nav-number">4.7.1.1.</span> <span class="nav-text">main.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#file-test"><span class="nav-number">4.7.1.2.</span> <span class="nav-text">file.test</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XIE QING</p>
  <div class="site-description" itemprop="description">怜我世人, 焚我残躯。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">闽ICP备18014770号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XIE QING</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
